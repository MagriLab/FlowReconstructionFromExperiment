{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results from physics-informed training \n",
    "    with 2D triangle wake\n",
    "- Plot sensors, interpolated, predicted.\n",
    "- Plot sensor loss, divergence, momentum residue (x and y)\n",
    "- Plot original data compared with predicted, show relative MSE.\n",
    "- Use probe, plot frequency at locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import h5py\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import flowrec.training_and_states as state_utils\n",
    "import flowrec.data as data_utils\n",
    "import flowrec.physics_and_derivatives as derivatives\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "from flowrec.utils import simulation\n",
    "from flowrec import losses\n",
    "from flowrec.utils.py_helper import slice_from_tuple\n",
    "from flowrec.utils.system import set_gpu\n",
    "set_gpu(0,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('../flowrec/utils/ppt.mplstyle')\n",
    "# plt.style.use('../flowrec/utils/a4.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dir = Path('../local_results/2dtriangle/sweep_loss_classic_fc2branch/dutiful-sweep-2') #\n",
    "# results_dir = Path('../local_results/2dtriangle/sweep_loss_3_fc2branch/fine-sweep-3') #\n",
    "# results_dir = Path('../local_results/2dtriangle/sweep_snr20_classic_fc2branch/vital-sweep-34') #\n",
    "# results_dir = Path('../local_results/2dtriangle/sweep_snr20_3_fc2branch/wise-sweep-23') #\n",
    "\n",
    "# results_dir = Path('../local_results/2dtriangle/repeat_noisy/snr20_classic/classic-224') #\n",
    "results_dir = Path('../test/classic-224') #\n",
    "\n",
    "if results_dir.exists():\n",
    "    ! ls $results_dir\n",
    "else:\n",
    "    raise ValueError('This directory does not exist.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load configurations and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(results_dir,'config.yml'),'r') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.UnsafeLoader)\n",
    "cfg.data_config.update({'data_dir':'.'+cfg.data_config.data_dir})\n",
    "\n",
    "with h5py.File(Path(results_dir,'results.h5'),'r') as hf:\n",
    "    loss_train = np.array(hf.get(\"loss_train\"))\n",
    "    loss_val = np.array(hf.get(\"loss_val\"))\n",
    "    loss_div = np.array(hf.get(\"loss_div\"))\n",
    "    loss_momentum = np.array(hf.get(\"loss_momentum\"))\n",
    "    loss_sensors = np.array(hf.get(\"loss_sensors\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_base = 132\n",
    "triangle_base_coords = [49,80]\n",
    "(ux,uy,pp) = simulation.read_data_2dtriangle(cfg.data_config.data_dir,x_base)\n",
    "x = np.stack([ux,uy,pp],axis=0)\n",
    "# remove parts where uz is not zero\n",
    "s = slice_from_tuple(cfg.data_config.slice_to_keep)\n",
    "x = x[s]\n",
    "\n",
    "# information about the grid\n",
    "datainfo = data_utils.DataMetadata(\n",
    "    re = cfg.data_config.re,\n",
    "    discretisation=[cfg.data_config.dt,cfg.data_config.dx,cfg.data_config.dy],\n",
    "    axis_index=[0,1,2],\n",
    "    problem_2d=True\n",
    ").to_named_tuple()\n",
    "\n",
    "rng = np.random.default_rng(cfg.data_config.randseed)\n",
    "if cfg.data_config.snr:\n",
    "    [x_train,x_val,x_test], _ = data_utils.data_partition(x,1,cfg.data_config.train_test_split,REMOVE_MEAN=cfg.data_config.remove_mean,randseed=cfg.data_config.randseed,SHUFFLE=cfg.data_config.shuffle) # Do not shuffle, do not remove mean for training with physics informed loss\n",
    "    [ux_train,uy_train,pp_train] = np.squeeze(np.split(x_train,3,axis=0))\n",
    "    [ux_val,uy_val,pp_val] = np.squeeze(np.split(x_val,3,axis=0))\n",
    "    [ux_test,uy_test,pp_test] = np.squeeze(np.split(x_test,3,axis=0))\n",
    "    u_train = np.stack((ux_train,uy_train,pp_train),axis=-1)\n",
    "    u_val = np.stack((ux_val,uy_val,pp_val),axis=-1)\n",
    "    u_test = np.stack((ux_test,uy_test,pp_test),axis=-1)\n",
    "\n",
    "    \n",
    "    std_data = np.std(x,axis=(1,2,3),ddof=1)\n",
    "    std_n = data_utils.get_whitenoise_std(cfg.data_config.snr,std_data)\n",
    "    noise_ux = rng.normal(scale=std_n[0],size=x[0,...].shape)\n",
    "    noise_uy = rng.normal(scale=std_n[1],size=x[1,...].shape)\n",
    "    noise_pp = rng.normal(scale=std_n[2],size=x[2,...].shape)\n",
    "    noise = np.stack([noise_ux,noise_uy,noise_pp],axis=0)\n",
    "    x = x + noise\n",
    "\n",
    "\n",
    "[x_train_n,x_val_n,x_test_n], _ = data_utils.data_partition(\n",
    "    x,\n",
    "    1,\n",
    "    cfg.data_config.train_test_split,\n",
    "    REMOVE_MEAN=cfg.data_config.remove_mean,\n",
    "    randseed=cfg.data_config.randseed,\n",
    "    SHUFFLE=cfg.data_config.shuffle\n",
    ") # Do not shuffle, do not remove mean for training with physics informed loss\n",
    "[ux_train_n,uy_train_n,pp_train_n] = np.squeeze(np.split(x_train_n,3,axis=0))\n",
    "[ux_val_n,uy_val_n,pp_val_n] = np.squeeze(np.split(x_val_n,3,axis=0))\n",
    "[ux_test_n,uy_test_n,pp_test_n] = np.squeeze(np.split(x_test_n,3,axis=0))\n",
    "u_train_n = np.stack((ux_train_n,uy_train_n,pp_train_n),axis=-1)\n",
    "u_val_n = np.stack((ux_val_n,uy_val_n,pp_val_n),axis=-1)\n",
    "u_test_n = np.stack((ux_test_n,uy_test_n,pp_test_n),axis=-1)\n",
    "\n",
    "pb_train = simulation.take_measurement_base(pp_train_n,ly=triangle_base_coords,centrex=0).reshape((cfg.data_config.train_test_split[0],-1))\n",
    "pb_val = simulation.take_measurement_base(pp_val_n,ly=triangle_base_coords,centrex=0).reshape((cfg.data_config.train_test_split[1],-1))\n",
    "pb_test = simulation.take_measurement_base(pp_test_n,ly=triangle_base_coords,centrex=0).reshape((cfg.data_config.train_test_split[2],-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## measure\n",
    "take_observation, insert_observation = cfg.case.observe(cfg.data_config, example_pred_snapshot=u_train[0,...],example_pin_snapshot=pb_train[0,...])\n",
    "observed_train, train_minmax = take_observation(u_train_n,init=True)\n",
    "observed_val, val_minmax = take_observation(u_val_n,init=True)\n",
    "observed_test, test_minmax = take_observation(u_test_n,init=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise input data\n",
    "Sensors and interpolated flow field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_plt = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_plot = np.empty_like(u_test)\n",
    "observed_plot.fill(np.nan)\n",
    "observed_plot = insert_observation(jnp.asarray(observed_plot),jnp.asarray(observed_test))\n",
    "\n",
    "measurements = []\n",
    "for i in range(observed_plot.shape[-1]):\n",
    "    measurements.append(observed_plot[t_plt,...,i][~np.isnan(observed_plot[t_plt,...,i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sensor coordinates\n",
    "sensors_empty = np.empty_like(u_train[[0],...])\n",
    "sensors_empty.fill(np.nan)\n",
    "\n",
    "grid_x,grid_y = np.mgrid[0:ux_train.shape[1], 0:ux_train.shape[2]]\n",
    "\n",
    "gridx1 = np.repeat(grid_x[None,:,:,None],3,axis=3)\n",
    "gridy1 = np.repeat(grid_y[None,:,:,None],3,axis=3)\n",
    "\n",
    "idx_x = take_observation(gridx1)\n",
    "idx_y = take_observation(gridy1)\n",
    "\n",
    "idx_x = insert_observation(jnp.asarray(sensors_empty),jnp.asarray(idx_x))[0,...]\n",
    "sensors_loc_x = []\n",
    "for i in range(idx_x.shape[-1]):\n",
    "    sensors_loc_x.append(idx_x[...,i][~np.isnan(idx_x[...,i])])\n",
    "\n",
    "idx_y = insert_observation(jnp.asarray(sensors_empty),jnp.asarray(idx_y))[0,...]\n",
    "sensors_loc_y = []\n",
    "for i in range(idx_y.shape[-1]):\n",
    "    sensors_loc_y.append(idx_y[...,i][~np.isnan(idx_y[...,i])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot true and interpolation\n",
    "fig = plt.figure(figsize=(36,15))\n",
    "axes = []\n",
    "axes.append(ImageGrid(fig,311,(1,3),share_all=True,cbar_mode='single'))\n",
    "axes.append(ImageGrid(fig,312,(1,3),share_all=True,cbar_mode='single'))\n",
    "axes.append(ImageGrid(fig,313,(1,3),share_all=True,cbar_mode='single'))\n",
    "\n",
    "for i in range(3):\n",
    "    sensors_loc = np.stack((sensors_loc_x[i].flatten(),sensors_loc_y[i].flatten()),axis=-1)\n",
    "    # data_interp = griddata(sensors_loc, measurements[i].flatten(), (grid_x,grid_y), method='cubic')\n",
    "    rbf = RBFInterpolator(sensors_loc,measurements[i])\n",
    "    data_interp = rbf(np.stack((grid_x.flatten(),grid_y.flatten()),axis=-1)).reshape(grid_x.shape)\n",
    "    ax = axes[i]\n",
    "    ax.axes_all[0].imshow(u_test[t_plt,...,i],'jet')\n",
    "    ax.axes_all[0].set_title('True data')\n",
    "    ax.axes_all[0].axis('off')\n",
    "    \n",
    "    ax.axes_all[1].imshow(u_test_n[t_plt,...,i],'jet')\n",
    "    ax.axes_all[1].set_title('Noisy data')\n",
    "    ax.axes_all[1].axis('off')\n",
    "\n",
    "    im = ax.axes_all[2].imshow(data_interp,'jet')\n",
    "    ax.axes_all[2].spy(observed_plot[t_plt,...,i],color='k',marker='x',markersize=5,alpha=0.6)\n",
    "    ax.axes_all[2].set_title('Interpolated')\n",
    "    ax.axes_all[2].axis('off')\n",
    "    ax.cbar_axes[0].colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(np.linspace(1.5,2.5,pb_train.shape[1]),pb_train[0,:])\n",
    "plt.title('Input to network')\n",
    "plt.ylabel('Pressure')\n",
    "plt.xlabel('y')\n",
    "plt.xlim([1.5,2.5])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss\n",
    "Plot different losses:\n",
    "- Sensors\n",
    "- Divergence\n",
    "- Momentum residue\n",
    "- Total physics loss\n",
    "- Total loss\n",
    "\n",
    "Also plot relative mse of the entire predicted flow field and compare with interpolated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,3,figsize=(15,5))\n",
    "fig.suptitle('Loss history')\n",
    "axes[0].plot(loss_div,label='Divergence')\n",
    "axes[0].plot(loss_momentum,label='Momentum')\n",
    "axes[0].plot(loss_sensors,label='Sensors')\n",
    "axes[0].legend()\n",
    "axes[0].set_yscale('log')\n",
    "axes[1].plot(loss_div+loss_momentum,label='Physics')\n",
    "axes[1].plot(loss_sensors,label='Sensors')\n",
    "axes[1].legend()\n",
    "axes[1].set_yscale('log')\n",
    "axes[2].plot(loss_train,label='Total loss in training')\n",
    "axes[2].plot(loss_div+loss_momentum+loss_sensors,label='Total loss without weighting')\n",
    "axes[2].legend()\n",
    "axes[2].set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = state_utils.restore_trainingstate(results_dir,'state')\n",
    "jax.tree_util.tree_map(lambda x: print(x.shape),state.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, make_model = cfg.case.select_model(datacfg=cfg.data_config, mdlcfg=cfg.model_config, traincfg=cfg.train_config)\n",
    "mdl = make_model(cfg.model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_train[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalise\n",
    "if cfg.data_config.normalise:\n",
    "    print(cfg.data_config.normalise)\n",
    "    [pb_train, pb_val, pb_test], _ = data_utils.normalise(pb_train, pb_val, pb_test, range=[train_minmax[-1],val_minmax[-1],test_minmax[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pb_train[0,:10])\n",
    "print(train_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(10)\n",
    "\n",
    "pb_train_batch = np.array_split(pb_train,2,0)\n",
    "pred_train = []\n",
    "for inn in pb_train_batch:\n",
    "    pred_train.append(mdl.apply(state.params,rng,inn,TRAINING=False))\n",
    "pred_train = np.concatenate(pred_train)\n",
    "pred_test = mdl.apply(state.params,rng,pb_test,TRAINING=False)\n",
    "if cfg.data_config.normalise:\n",
    "    pred_train = data_utils.unnormalise_group(pred_train, train_minmax, axis_data=-1, axis_range=0)\n",
    "    pred_test = data_utils.unnormalise_group(pred_test, test_minmax, axis_data=-1, axis_range=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate physics loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_d_test = derivatives.div_field(pred_test[...,:-1],datainfo)\n",
    "l_m_test = derivatives.momentum_residual_field(pred_test,datainfo)\n",
    "\n",
    "\n",
    "l_d_train = derivatives.div_field(pred_train[...,:-1],datainfo)\n",
    "l_m_train = derivatives.momentum_residual_field(pred_train,datainfo)\n",
    "\n",
    "\n",
    "l_d_true = derivatives.div_field(u_test[...,:-1],datainfo)\n",
    "l_m_true = derivatives.momentum_residual_field(u_test,datainfo)\n",
    "\n",
    "\n",
    "l_d_noisy = derivatives.div_field(u_test_n[...,:-1],datainfo)\n",
    "l_m_noisy = derivatives.momentum_residual_field(u_test_n,datainfo)\n",
    "\n",
    "# fig = plt.figure(figsize=(12,6))\n",
    "# grid = ImageGrid(fig,111,(1,3),cbar_mode='each',axes_pad=0.3,cbar_pad=0.05)\n",
    "# for ax, cax, plt_data in zip(grid.axes_all, grid.cbar_axes, [l_d_true, l_m_true[0,...], l_m_true[1,...]]):\n",
    "#     im = ax.imshow(np.mean(plt_data,axis=0),'jet')\n",
    "#     cax.colorbar(im)\n",
    "# fig.suptitle('Time-averaged divergence, momentum residue x and y for true data.')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot comparison between prediction and True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,15))\n",
    "set_name = ['$u_x$','$u_y$','$p$']\n",
    "\n",
    "# predicted\n",
    "grid1 = ImageGrid(fig,131,(3,1),cbar_mode='each',axes_pad=(0.02,0.3))\n",
    "mse_plane = np.einsum('t x y i -> x y i', (pred_test-u_test)**2)/cfg.data_config.train_test_split[2]\n",
    "for i, (ax,cax) in enumerate(zip(grid1[:3],grid1.cbar_axes[:3])):\n",
    "    im = ax.imshow(pred_test[t_plt,:,:,i],'jet')\n",
    "    ax.set_title(f'Predicted {set_name[i]}')\n",
    "    cax.colorbar(im)\n",
    "    ax.grid()\n",
    "\n",
    "# true\n",
    "grid2 = ImageGrid(fig,132,(3,1),cbar_mode='each',axes_pad=(0.02,0.3))\n",
    "mse_plane = np.einsum('t x y i -> x y i', (pred_test-u_test)**2)/cfg.data_config.train_test_split[2]\n",
    "for i, (ax,cax) in enumerate(zip(grid2[:3],grid2.cbar_axes[:3])):\n",
    "    im = ax.imshow(u_test[t_plt,:,:,i],'jet')\n",
    "    ax.set_title(f'True {set_name[i]}')\n",
    "    cax.colorbar(im)\n",
    "    ax.grid()\n",
    "\n",
    "# loss\n",
    "grid3 = ImageGrid(fig,133,(3,1),cbar_mode='each',axes_pad=(0.02,0.3))\n",
    "mse_plane = np.einsum('t x y i -> x y i', (pred_test-u_test)**2)/cfg.data_config.train_test_split[2]\n",
    "for i, (ax,cax) in enumerate(zip(grid3[:3],grid3.cbar_axes[:3])):\n",
    "    im = ax.imshow(mse_plane[:,:,i],'jet')\n",
    "    ax.set_title(f'relative error = {losses.relative_error(pred_test[...,i],u_test[...,i]):.5f}')\n",
    "    cax.colorbar(im)\n",
    "    ax.grid()\n",
    "\n",
    "fig.suptitle(f'Columns showing instantaneous prediction, true data at t={t_plt} and time averaged MSE.')\n",
    "\n",
    "for axpred, axtrue in zip(grid1.axes_all,grid2.axes_all):\n",
    "    [impred] = axpred.get_images()\n",
    "    [imtrue] = axtrue.get_images()\n",
    "    climpred = impred.get_clim()\n",
    "    climtrue = imtrue.get_clim()\n",
    "    impred.set_clim(min(climpred[0],climtrue[0]),max(climpred[1],climtrue[1]))\n",
    "    imtrue.set_clim(min(climpred[0],climtrue[0]),max(climpred[1],climtrue[1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Physics loss comparison\n",
    "\n",
    "Calculate residual of the interpolated data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_observed_test = np.empty_like(u_test)\n",
    "temp_observed_test.fill(np.nan)\n",
    "temp_observed_test = insert_observation(jnp.asarray(temp_observed_test),jnp.asarray(observed_test)) # observed_test is noisy if"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_interp = []\n",
    "\n",
    "_locs = np.stack((grid_x.flatten(),grid_y.flatten()),axis=-1)\n",
    "\n",
    "for i in range(3):\n",
    "    sensors_loc = np.stack((sensors_loc_x[i].flatten(),sensors_loc_y[i].flatten()),axis=-1)\n",
    "    for j in range(cfg.data_config.train_test_split[2]):\n",
    "        temp_measurement = temp_observed_test[j,...,i][~np.isnan(temp_observed_test[j,...,i])]\n",
    "        rbf = RBFInterpolator(sensors_loc,temp_measurement.flatten(),kernel='thin_plate_spline')\n",
    "        _interp = rbf(_locs).reshape(grid_x.shape)\n",
    "        compare_interp.append(_interp)\n",
    "        # compare_interp.append(\n",
    "            # griddata(sensors_loc, temp_measurement.flatten(), (grid_x,grid_y), method='cubic')\n",
    "        # )\n",
    "compare_interp = np.array(compare_interp)\n",
    "compare_interp = np.stack((compare_interp[:cfg.data_config.train_test_split[2],...],compare_interp[cfg.data_config.train_test_split[2]:2*cfg.data_config.train_test_split[2],...],compare_interp[2*cfg.data_config.train_test_split[2]:3*cfg.data_config.train_test_split[2],...]),axis=-1)\n",
    "nb_elements = np.count_nonzero(~np.isnan(compare_interp[1,...,0]))\n",
    "compare_interp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_physics = derivatives.div_field(compare_interp[...,:-1],datainfo=datainfo) + np.sum(derivatives.momentum_residual_field(compare_interp,datainfo=datainfo),axis=0)\n",
    "# interp_physics = np.nan_to_num(interp_physics)\n",
    "interp_physics.shape\n",
    "# this is noisy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_value = 0\n",
    "t_compare = 20\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "fig.suptitle(f'Instantaneous comparison at t={t_compare}')\n",
    "grid = ImageGrid(fig,(0,0,1,0.95),(3,4),cbar_mode='each',axes_pad=(0.5,0.5),cbar_pad=0.005)\n",
    "ax = grid.axes_all\n",
    "cax = grid.cbar_axes\n",
    "\n",
    "clim_min = []\n",
    "clim_max = []\n",
    "\n",
    "#first row\n",
    "ax[0].set_title('True')\n",
    "im = ax[0].imshow(u_test[t_compare,...,which_value])\n",
    "clim = im.get_clim()\n",
    "clim_min.append(clim[0])\n",
    "clim_max.append(clim[1])\n",
    "cax[0].colorbar(im)\n",
    "ax[1].set_title('Predicted')\n",
    "im = ax[1].imshow(pred_test[t_compare,...,which_value])\n",
    "clim = im.get_clim()\n",
    "clim_min.append(clim[0])\n",
    "clim_max.append(clim[1])\n",
    "cax[1].colorbar(im)\n",
    "ax[2].set_title('Interpolated (cubic)')\n",
    "im = ax[2].imshow(compare_interp[t_compare,...,which_value])\n",
    "clim = im.get_clim()\n",
    "clim_min.append(clim[0])\n",
    "clim_max.append(clim[1])\n",
    "cax[2].colorbar(im)\n",
    "ax[3].set_title('Noisy')\n",
    "im = ax[3].imshow(u_test_n[t_compare,...,which_value])\n",
    "clim = im.get_clim()\n",
    "clim_min.append(clim[0])\n",
    "clim_max.append(clim[1])\n",
    "cax[3].colorbar(im)\n",
    "\n",
    "for axis in ax[:4]:\n",
    "    [im] = axis.get_images()\n",
    "    im.set_clim(min(clim_min),max(clim_max))\n",
    "\n",
    "\n",
    "#second row\n",
    "ax[4].axis('off')\n",
    "cax[4].axis('off')\n",
    "ax[5].set_title(f'inst. MSE = {losses.mse(pred_test[t_compare,...,which_value],u_test[t_compare,...,which_value]):.7f}')\n",
    "im = ax[5].imshow((pred_test[t_compare,...,which_value]-u_test[t_compare,...,which_value])**2,'jet')\n",
    "cax[5].colorbar(im)\n",
    "mse_interp = np.sum(np.nan_to_num(compare_interp[t_compare,...,which_value] - u_test[t_compare,...,which_value])**2)/nb_elements\n",
    "ax[6].set_title(f'inst. MSE = {mse_interp:.7f}')\n",
    "im = ax[6].imshow((compare_interp[t_compare,...,which_value]-u_test[t_compare,...,which_value])**2,'jet')\n",
    "cax[6].colorbar(im)\n",
    "ax[7].set_title(f'inst. MSE = {losses.mse(u_test_n[t_compare,...,which_value],u_test[t_compare,...,which_value]):.7f}')\n",
    "im = ax[7].imshow((u_test_n[t_compare,...,which_value]-u_test[t_compare,...,which_value])**2,'jet')\n",
    "cax[7].colorbar(im)\n",
    "\n",
    "\n",
    "# third row\n",
    "ax[8].set_title(f'inst. residue\\n= {np.mean((l_d_true+l_m_true[0,...]+l_m_true[1,...])[t_compare,...]):.7f}')\n",
    "# im = ax[8].imshow(np.abs((l_mx_true)[t_compare,...]),'jet')\n",
    "im = ax[8].imshow(np.abs((l_d_true+l_m_true[0,...]+l_m_true[1,...])[t_compare,...]),'jet')\n",
    "cax[8].colorbar(im)\n",
    "ax[9].set_title(f'inst. residue\\n= {np.mean((l_d_test+l_m_test[0,...]+l_m_test[1,...])[t_compare,...]):.7f}')\n",
    "im = ax[9].imshow(np.abs((l_d_test+l_m_test[0,...]+l_m_test[1,...])[t_compare,...]),'jet')\n",
    "cax[9].colorbar(im)\n",
    "ax[10].set_title(f'inst. residue\\n= {np.sum(np.nan_to_num(interp_physics[t_compare,:,:])/nb_elements):.7f}')\n",
    "im = ax[10].imshow(np.abs(interp_physics[t_compare,...]),'jet')\n",
    "cax[10].colorbar(im)\n",
    "ax[11].set_title(f'inst. residue\\n= {np.mean((l_d_noisy+l_m_noisy[0,...]+l_m_noisy[1,...])[t_compare,...]):.7f}')\n",
    "im = ax[11].imshow(np.abs((l_d_noisy+l_m_noisy[0,...]+l_m_noisy[1,...])[t_compare,...]),'jet')\n",
    "cax[11].colorbar(im)\n",
    "\n",
    "\n",
    "for ax in grid:\n",
    "    ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses.mse(l_d_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datainfo.axis_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vorticity(u, datainfo):\n",
    "    step_space = datainfo.discretisation[1:]\n",
    "    axis_space = datainfo.axis_index[1:]\n",
    "    u = jnp.moveaxis(u[...],-1,0) # move velocity axis to 0\n",
    "    v_derivative1 = jax.vmap(derivatives.derivative1,(0,None,None),0)\n",
    "    def _didj(de_fun,inn):\n",
    "        didj_T = de_fun(inn,datainfo.dx,datainfo.axx).reshape((-1,)+inn.shape)\n",
    "        for j in range (1,u.shape[0]):\n",
    "            didj_T = jnp.concatenate(\n",
    "                (\n",
    "                didj_T,\n",
    "                de_fun(inn,step_space[j],axis_space[j]).reshape((-1,)+inn.shape)\n",
    "                ),\n",
    "                axis=0\n",
    "            )\n",
    "        return didj_T # for de_fun = v_derivative1 and inn=u -> [j,i,t,x,y,z]\n",
    "    \n",
    "    dui_dxj_T = _didj(v_derivative1, u) # [j,i,t,x,y,z]\n",
    "\n",
    "    vort = dui_dxj_T[0,1,...] - dui_dxj_T[1,0,...]\n",
    "\n",
    "    if len(axis_space) == 3:\n",
    "        vort = vort + (dui_dxj_T[1,2] - dui_dxj_T[2,1]) + (dui_dxj_T[2,0]-dui_dxj_T[0,2])\n",
    "\n",
    "    return vort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vort_train_n = derivatives.vorticity(u_train_n[...,:-1],datainfo)\n",
    "vort_train = derivatives.vorticity(u_train[...,:-1],datainfo)\n",
    "vort_pred = derivatives.vorticity(pred_train[...,:-1],datainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstep = 15\n",
    "fig = plt.figure(figsize=(8,7))\n",
    "grid = ImageGrid(fig,111,(2,3),share_all=True,cbar_location='right',cbar_mode='single')\n",
    "vmax = np.max(vort_train[0:3*tstep:tstep,...])\n",
    "vmin = np.min(vort_train[0:3*tstep:tstep,...])\n",
    "axes = grid.axes_all\n",
    "for i in range(3):\n",
    "    im0 = axes[i].imshow(vort_train_n[i*tstep,...].T,vmax=vmax,vmin=vmin)\n",
    "    im1 = axes[i+3].imshow(vort_pred[i*tstep,...].T,vmax=vmax,vmin=vmin)\n",
    "    axes[i+3].set(xlabel=f'$t={tstep*i}$',xticks=[])\n",
    "    cbar = grid.cbar_axes[i].colorbar(im0,label='Vorticity')\n",
    "axes[0].set(yticks=[],ylabel='True')\n",
    "axes[3].set(yticks=[],ylabel='Pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,3,figsize=(10,3))\n",
    "axes[0].set_title('mean of the noisy training data\\n')\n",
    "im0 = axes[0].imshow(jnp.mean(u_train_n,axis=0)[...,0],vmax=1.6,vmin=-0.3)\n",
    "plt.colorbar(im0)\n",
    "axes[1].set_title('mean of the prediction, \\nand location of the sensors')\n",
    "im1 = axes[1].imshow(jnp.mean(pred_train,axis=0)[...,0],vmax=1.6,vmin=-0.3)\n",
    "# axes[1].spy(observed_plot[t_plt,...,0],marker='x',markersize=2,c='k')\n",
    "plt.colorbar(im1)\n",
    "axes[2].set_title('mean of interpolation\\n')\n",
    "im2 = axes[2].imshow(jnp.mean(compare_interp,axis=0)[...,0],vmax=1.6,vmin=-0.3)\n",
    "plt.colorbar(im2)\n",
    "plt.show()\n",
    "print('Relative L2 of mean: ', losses.mse(np.mean(pred_test,axis=0),np.mean(u_test,axis=0))/losses.mse(np.mean(u_test,axis=0)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probe location\n",
    "probe_loc = [210,60]\n",
    "\n",
    "fig = plt.figure(figsize=(5,7))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.spy(observed_plot[t_plt,...,0],marker='x',markersize=2,c='k')\n",
    "ax.imshow(ux_test[0,:,:],'jet',alpha=0.5)\n",
    "ax.scatter(probe_loc[1],probe_loc[0],zorder=20,c='r')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequencies in true data\n",
    "probe_ux_true = ux_test[:,probe_loc[0],probe_loc[1]]\n",
    "probe_uy_true = uy_test[:,probe_loc[0],probe_loc[1]]\n",
    "probe_p_true = pp_test[:,probe_loc[0],probe_loc[1]]\n",
    "\n",
    "freq = np.fft.fftfreq(len(probe_ux_true),d=0.0002*1250)\n",
    "f_ux_true = np.fft.fft(probe_ux_true-np.mean(probe_ux_true))/len(probe_ux_true)\n",
    "f_uy_true = np.fft.fft(probe_uy_true-np.mean(probe_uy_true))/len(probe_uy_true)\n",
    "f_p_true = np.fft.fft(probe_p_true-np.mean(probe_p_true))/len(probe_p_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequencies\n",
    "probe_ux_pred = pred_test[:,probe_loc[0],probe_loc[1],0]\n",
    "probe_uy_pred = pred_test[:,probe_loc[0],probe_loc[1],1]\n",
    "probe_p_pred = pred_test[:,probe_loc[0],probe_loc[1],2]\n",
    "\n",
    "# freq = np.fft.fftfreq(len(probe_ux_pred),d=0.0002*1250)\n",
    "f_ux_pred = np.fft.fft(probe_ux_pred-np.mean(probe_ux_pred))/len(probe_ux_pred)\n",
    "f_uy_pred = np.fft.fft(probe_uy_pred-np.mean(probe_uy_pred))/len(probe_uy_pred)\n",
    "f_p_pred = np.fft.fft(probe_p_pred-np.mean(probe_p_pred))/len(probe_p_pred)\n",
    "\n",
    "# frequencies\n",
    "probe_ux_interp = compare_interp[:,probe_loc[0],probe_loc[1],0]\n",
    "probe_uy_interp = compare_interp[:,probe_loc[0],probe_loc[1],1]\n",
    "probe_p_interp = compare_interp[:,probe_loc[0],probe_loc[1],2]\n",
    "\n",
    "# freq = np.fft.fftfreq(len(probe_ux_interp),d=0.0002*1250)\n",
    "f_ux_interp = np.fft.fft(probe_ux_interp-np.mean(probe_ux_interp))/len(probe_ux_interp)\n",
    "f_uy_interp = np.fft.fft(probe_uy_interp-np.mean(probe_uy_interp))/len(probe_uy_interp)\n",
    "f_p_interp = np.fft.fft(probe_p_interp-np.mean(probe_p_interp))/len(probe_p_interp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(1,3,figsize=(15,4))\n",
    "# ax[0].set(title='Frequency spectrum of prediction',xlabel='f',xlim=[0,2])\n",
    "# ax[0].plot(freq[:int(len(freq)/2)], np.abs(f_ux_pred)[:int(len(freq)/2)],label='ux')\n",
    "# ax[0].plot(freq[:int(len(freq)/2)], np.abs(f_uy_pred)[:int(len(freq)/2)],label='uy')\n",
    "# ax[0].plot(freq[:int(len(freq)/2)], np.abs(f_p_pred)[:int(len(freq)/2)],label='p')\n",
    "# ax[0].legend()\n",
    "# ax[0].minorticks_on()\n",
    "# ax[0].grid(True,which='both',axis='x')\n",
    "\n",
    "# ax[1].set(title='Frequency spectrum of interpolated data',xlabel='f',xlim=[0,2])\n",
    "# ax[1].plot(freq[:int(len(freq)/2)], np.abs(f_ux_interp)[:int(len(freq)/2)],label='ux')\n",
    "# ax[1].plot(freq[:int(len(freq)/2)], np.abs(f_uy_interp)[:int(len(freq)/2)],label='uy')\n",
    "# ax[1].plot(freq[:int(len(freq)/2)], np.abs(f_p_interp)[:int(len(freq)/2)],label='p')\n",
    "# ax[1].legend()\n",
    "# ax[1].minorticks_on()\n",
    "# ax[1].grid(True,which='both',axis='x')\n",
    "\n",
    "# ax[2].set(title='Frequency spectrum of true data',xlabel='f',xlim=[0,2])\n",
    "# ax[2].plot(freq[:int(len(freq)/2)], np.abs(f_ux_true)[:int(len(freq)/2)],label='ux')\n",
    "# ax[2].plot(freq[:int(len(freq)/2)], np.abs(f_uy_true)[:int(len(freq)/2)],label='uy')\n",
    "# ax[2].plot(freq[:int(len(freq)/2)], np.abs(f_p_true)[:int(len(freq)/2)],label='p')\n",
    "# ax[2].legend()\n",
    "# ax[2].minorticks_on()\n",
    "# ax[2].grid(True,which='both',axis='x')\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,5))\n",
    "ax.set(title='Frequency spectrum', xlabel='f', xlim=[0,2])\n",
    "ax.plot(freq[:int(len(freq)/2)], np.abs(f_ux_pred)[:int(len(freq)/2)],label='ux_pred',c='g',linestyle='-')\n",
    "ax.plot(freq[:int(len(freq)/2)], np.abs(f_uy_pred)[:int(len(freq)/2)],label='uy_pred',c='k',linestyle='-')\n",
    "ax.plot(freq[:int(len(freq)/2)], np.abs(f_p_pred)[:int(len(freq)/2)],label='p_pred',c='r',linestyle='-')\n",
    "ax.plot(freq[:int(len(freq)/2)], np.abs(f_ux_interp)[:int(len(freq)/2)],label='ux_interp',c='g',linestyle='--')\n",
    "ax.plot(freq[:int(len(freq)/2)], np.abs(f_uy_interp)[:int(len(freq)/2)],label='uy_interp',c='k',linestyle='--')\n",
    "ax.plot(freq[:int(len(freq)/2)], np.abs(f_p_interp)[:int(len(freq)/2)],label='p_interp',c='r',linestyle='--')\n",
    "ax.plot(freq[:int(len(freq)/2)], np.abs(f_ux_true)[:int(len(freq)/2)],label='ux',c='g',linestyle='',marker='x')\n",
    "ax.plot(freq[:int(len(freq)/2)], np.abs(f_uy_true)[:int(len(freq)/2)],label='uy',c='k',linestyle='',marker='x')\n",
    "ax.plot(freq[:int(len(freq)/2)], np.abs(f_p_true)[:int(len(freq)/2)],label='p',c='r',linestyle='',marker='x')\n",
    "ax.minorticks_on()\n",
    "ax.legend()\n",
    "ax.grid(True,which='both',axis='x')\n",
    "ax.set_xlim([0,0.75])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Relative MSE for prediction in testing: ', losses.relative_error(pred_test,u_test))\n",
    "print('Relative MSE for prediction in training: ', losses.relative_error(pred_train,u_train))\n",
    "print('Relative MSE for interpolation in testing: ', losses.relative_error(compare_interp,u_test))\n",
    "print('Relative MSE for noisy testing set: ', losses.relative_error(u_test_n,u_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## residue averaged over time\n",
    "rmse_true = np.mean((l_d_true+l_m_true[0,...]+l_m_true[1,...])**2)\n",
    "rmse_pred = np.mean((l_d_test+l_m_test[0,...]+l_m_test[1,...])**2)\n",
    "rmse_train = np.mean((l_d_train+l_m_train[0,...]+l_m_train[1,...])**2)\n",
    "rmse_interp = np.sum(np.nan_to_num(interp_physics**2))/nb_elements\n",
    "rmse_noisy = np.mean((l_d_noisy+l_m_noisy[0,...]+l_m_noisy[1,...])**2)\n",
    "print('Residual**2 averaged over space and time:')\n",
    "print(f'True data: {rmse_true:.7f}')\n",
    "print(f'predicted training data: {rmse_train:.7f}')\n",
    "print(f'predicted testing data: {rmse_pred:.7f}')\n",
    "print(f'interp data: {rmse_interp:.7f}')\n",
    "print(f'noisy data: {rmse_noisy:.7f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_energy = np.sum(pred_test**2)/np.sum(u_test**2)\n",
    "print('% energy of the testing set: ', percent_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_test_nonan = []\n",
    "for i in range(3):\n",
    "    mask = ~np.isnan(compare_interp[0,...,i])\n",
    "    interp_test_nonan.append(compare_interp[...,i][:,mask])\n",
    "\n",
    "fig,axes = plt.subplots(1,3,figsize=(8,4))\n",
    "for i,var in zip(range(3),['u','v','p']):\n",
    "    counts_true,bins_true = np.histogram(u_test[...,i].flatten()-np.mean(u_test[...,i].flatten()), density=True, bins='auto')\n",
    "    axes[i].stairs(counts_true,bins_true,label='true',linewidth=3, color='#808080',alpha=0.5)\n",
    "    counts,bins = np.histogram(pred_test[...,i].flatten()-np.mean(pred_test[...,i].flatten()), density=True, bins='auto')\n",
    "    axes[i].stairs(counts,bins,label='prediction',color='k')\n",
    "    counts,bins = np.histogram(interp_test_nonan[i].flatten()-np.mean(interp_test_nonan[i].flatten()), density=True, bins='auto')\n",
    "    axes[i].stairs(counts,bins,label='interpolation',color='r',linestyle='--')\n",
    "    axes[i].set(title=var)\n",
    "axes[0].set_ylabel('Probability density')\n",
    "axes[2].legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "freq_data_overall = np.einsum('t x y u -> t u', np.abs(np.fft.fft(u_test-np.mean(u_test,axis=0,keepdims=True),axis=0)))\n",
    "# freq_data_overall = freq_data_overall / np.std(freq_data_overall,axis=0)\n",
    "freq_pred_overall = np.einsum('t x y u -> t u', np.abs(np.fft.fft(pred_test-np.mean(pred_test,axis=0,keepdims=True),axis=0)))\n",
    "# freq_pred_overall = freq_pred_overall / np.std(freq_pred_overall,axis=0)\n",
    "freq_interp = []\n",
    "for i in range(3):\n",
    "    _interp = np.einsum('t n -> t', np.abs(np.fft.fft(interp_test_nonan[i]-np.mean(interp_test_nonan[i]),axis=0)))\n",
    "    # _interp = _interp / np.std(_interp)\n",
    "    freq_interp.append(_interp)\n",
    "\n",
    "fig,axes = plt.subplots(1,3,figsize=(8,4),sharex=True)\n",
    "for i,var in zip(range(3),['u','v','p']):\n",
    "    axes[i].plot(freq[:int(len(freq)/2)], freq_data_overall[:int(len(freq)/2),i],label='true',linewidth=3,color='#808080',alpha=0.5)\n",
    "    axes[i].plot(freq[:int(len(freq)/2)], freq_pred_overall[:int(len(freq)/2),i],label='prediction',color='k',linewidth=1)\n",
    "    axes[i].plot(freq[:int(len(freq)/2)], freq_interp[i][:int(len(freq)/2)],label='interpolation',color='r',linewidth=1,linestyle='--')\n",
    "    axes[i].set(title=var,xlabel='frequency',xlim=[0,1.0])\n",
    "axes[2].legend()\n",
    "axes[0].set(ylabel='energy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fftn_pred = np.fft.fftn(pred_test-np.mean(pred_test,axis=0,keepdims=True),axes=[1,2])\n",
    "fftn_true = np.fft.fftn(u_test-np.mean(u_test,axis=0,keepdims=True),axes=[1,2])\n",
    "\n",
    "freqx = np.fft.fftfreq(250,d=datainfo.dx)\n",
    "freqx = freqx[:int(len(freqx)/2)]\n",
    "freqy = np.fft.fftfreq(129,d=datainfo.dy)\n",
    "freqy = freqy[:int(len(freqy)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_value = 2\n",
    "fig,axes = plt.subplots(1,2,figsize=(8,4),sharex=True,sharey=True)\n",
    "\n",
    "im0 = axes[0].imshow(np.log(np.mean(np.abs(fftn_pred[:,:,:,which_value][:,:len(freqx),:len(freqy)]),axis=0)), \n",
    "    extent=[freqy[0],freqy[-1],freqx[0],freqx[-1]]\n",
    ")\n",
    "axes[0].set(xlabel='$f_y$ (Hz)',ylabel='$f_x$ (Hz)',title='Prediction')\n",
    "plt.colorbar(im0,label='$log((m/s)^2/Hz)$')\n",
    "\n",
    "im1 = axes[1].imshow(np.log(np.mean(np.abs(fftn_true[:,:,:,which_value][:,:len(freqx),:len(freqy)]),axis=0)), \n",
    "    extent=[freqy[0],freqy[-1],freqx[0],freqx[-1]]\n",
    ")\n",
    "plt.colorbar(im1,label='$log((m/s)^2/Hz)$')\n",
    "axes[1].set(title='True')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ðŸ¤¯ END ðŸ¤¯\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
