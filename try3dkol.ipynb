{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from flowrec.utils.system import set_gpu\n",
    "set_gpu(0,1)\n",
    "import jax\n",
    "import jax.numpy\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('./flowrec/utils/ppt.mplstyle')\n",
    "from matplotlib import mlab\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from pathlib import Path\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flowrec.utils.simulation import read_data_kolsol, kolsol_forcing_term\n",
    "import flowrec.physics_and_derivatives as derivatives\n",
    "import flowrec.losses as losses\n",
    "from flowrec.data import DataMetadata, normalise, unnormalise_group\n",
    "from flowrec.utils.py_helper import slice_from_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_p, re, dt = read_data_kolsol('./local_data/kolmogorov/dim3_re34_k32_f4_dt01_grid64_189.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datainfo = DataMetadata(\n",
    "    re=re,\n",
    "    discretisation=[dt,2*np.pi/64,2*np.pi/64,2*np.pi/64],\n",
    "    axis_index=[0,1,2,3],\n",
    "    problem_2d=False\n",
    ").to_named_tuple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3,figsize=(10,3))\n",
    "axes[0].imshow(np.mean(u_p[:,:,:,0,0],axis=0).T)\n",
    "axes[0].set(xlabel='x', ylabel='y')\n",
    "axes[1].imshow(np.mean(u_p[:,:,0,:,0],axis=0).T)\n",
    "axes[1].set(xlabel='x',ylabel='z')\n",
    "axes[2].imshow(np.mean(u_p[:,0,:,:,0],axis=0).T)\n",
    "axes[2].set(xlabel='y',ylabel='z')\n",
    "fig.suptitle('average over time')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig,axes = plt.subplots(1,3, figsize=(10,3))\n",
    "axes[0].imshow(np.mean(u_p[:,20,:,:,0], axis=0).T)\n",
    "axes[0].set(xlabel='y', ylabel='z', title='x=20')\n",
    "axes[1].imshow(np.mean(u_p[:,40,:,:,0], axis=0).T)\n",
    "axes[1].set(xlabel='y', ylabel='z', title='x=40')\n",
    "axes[2].imshow(np.mean(u_p[:,60,:,:,0], axis=0).T)\n",
    "axes[2].set(xlabel='y', ylabel='z', title='x=60')\n",
    "plt.show()\n",
    "fig,axes = plt.subplots(1,3, figsize=(10,3))\n",
    "axes[0].imshow(np.mean(u_p[:,:,:,20,0], axis=0).T)\n",
    "axes[0].set(xlabel='x', ylabel='y', title='z=20')\n",
    "axes[1].imshow(np.mean(u_p[:,:,:,40,0], axis=0).T)\n",
    "axes[1].set(xlabel='x', ylabel='z', title='z=40')\n",
    "axes[2].imshow(np.mean(u_p[:,:,:,60,0], axis=0).T)\n",
    "axes[2].set(xlabel='x', ylabel='z', title='z=60')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.mean(u_p[...,0], axis=(0,1,3)), label='y')\n",
    "plt.plot(np.mean(u_p[...,0], axis=(0,1,2)), label='z')\n",
    "plt.plot(np.mean(u_p[...,0], axis=(0,2,3)), label='x')\n",
    "plt.title('x and z are the homogenous direction')\n",
    "plt.xlabel('x/y/z')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses.divergence(u_p[...,:-1],datainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing = kolsol_forcing_term(4, 64, 3)\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(forcing[0,0,0,:,:].T)\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.plot(forcing[0,0,0,:,0],label='overy')\n",
    "plt.plot(forcing[0,0,:,0,0],label='overx')\n",
    "plt.plot(forcing[0,0,0,0,:],label='overz')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfield = derivatives.momentum_residual_field(u_p[:200,...], datainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(mfield[0,100,10,:,:].T)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.imshow((mfield+forcing[...,[0]])[0,100,10,:,:].T)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(losses.momentum_loss(u_p[:200,...],datainfo,forcing=forcing))\n",
    "print(losses.momentum_loss(u_p[:200,...],datainfo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jax.default_device(jax.devices('cpu')[0]):\n",
    "    dissi = derivatives.dissipation(u_p[...,:-1], datainfo)\n",
    "d_avg = np.mean(dissi.reshape(u_p.shape[0],-1), axis=1)\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.plot(d_avg)\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('dissipation')\n",
    "_, axes = plt.subplots(1,3,figsize=(6,2))\n",
    "axes[0].plot(d_avg[:-100],d_avg[100:])\n",
    "axes[1].plot(d_avg[:-300],d_avg[300:])\n",
    "axes[2].plot(d_avg[:-500],d_avg[500:])\n",
    "plt.show()\n",
    "pxx, freqs = mlab.psd(d_avg-np.mean(d_avg),Fs=datainfo.dt)\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.title(f'PSD of 3D kolmogorov flow Re={re}')\n",
    "plt.semilogx(freqs,pxx,linewidth=1,marker='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flowrec.signal import autocorr\n",
    "ac = autocorr(d_avg)\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(ac)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_plane = 32\n",
    "inns_loc = np.s_[:,0,:,:,-1]\n",
    "inns = u_p[inns_loc]\n",
    "print(inns.shape)\n",
    "y_loc = np.s_[:,:,:,[z_plane],:-1]\n",
    "yref = u_p[y_loc]\n",
    "print(yref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "measured = np.empty_like(u_p[:10,...])\n",
    "measured[inns_loc] = inns[:10,...]\n",
    "measured[y_loc] = yref[:10,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(measured[0,:,:,z_plane,0].T, origin='lower')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.spy(measured[0,:,:,z_plane,-1].T,alpha=0.3, origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,4,figsize=(12,3))\n",
    "for i,ax in enumerate(axes):\n",
    "    counts,bins = np.histogram(u_p[...,i].flatten()-np.mean(u_p[...,i].flatten()), density=True, bins='auto')\n",
    "    ax.stairs(counts,bins,label='all',linewidth=2)\n",
    "    counts_plane,bins_plane = np.histogram(u_p[...,z_plane,i].flatten()-np.mean(u_p[...,z_plane,i].flatten()), density=True, bins='auto')\n",
    "    ax.stairs(counts_plane,bins_plane,label='plane',linestyle='--')\n",
    "axes[0].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flowrec.training_and_states as train\n",
    "import optax\n",
    "from train_config.train_options import optimizer as optimiser_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1297)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flowrec.models.feedforward import Model as FFMDL\n",
    "from flowrec.models.feedforward import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl1 = FFMDL(\n",
    "    layers=[128,256,1024,yref[0,...].size],\n",
    "    name = 'mdl1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "params1 = mdl1.init(key,inns[:10,:,z_plane])\n",
    "scheduler1 = optimiser_options.get_scheduler('exponential_decay', lr)\n",
    "optimiser1 = optax.adamw(learning_rate=scheduler1)\n",
    "opt_state1 = optimiser1.init(params1)\n",
    "state1 = train.TrainingState(params=params1, opt_state=opt_state1)\n",
    "mdl1.apply(state1.params, key, inns[:10,:,z_plane]).shape\n",
    "update1 = train.generate_update_fn(\n",
    "    mdl1.apply,\n",
    "    optimiser1,\n",
    "    losses.loss_mse,\n",
    ")\n",
    "_l, _ = update1(state1, key, inns[:10,:,z_plane], yref[:10,...].reshape((10,-1)))\n",
    "print(_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1 = []\n",
    "best_l = jnp.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batchsize = 200\n",
    "for i in range(n_epochs):\n",
    "    [key] = jax.random.split(key,1)\n",
    "    l_epoch = []\n",
    "    j = 0\n",
    "    while (j+1)*batchsize <= u_p.shape[0] :\n",
    "        _l, state1 = update1(state1, key, inns[j*batchsize:(j+1)*batchsize,:,z_plane], yref[j*batchsize:(j+1)*batchsize,...].reshape((batchsize,-1)))\n",
    "        j += 1\n",
    "        l_epoch.append(_l)\n",
    "    l = np.mean(l_epoch)\n",
    "    hist1.append(l)\n",
    "    if i % 20 == 0:\n",
    "        print(f'epoch {i}, loss {l}')\n",
    "    if l < best_l:\n",
    "        best_state1 = state1\n",
    "        best_l = l\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.loglog(hist1)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_slice = mdl1.apply(best_state1.params, None, inns[:,:,z_plane]).reshape(yref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_step = 80\n",
    "component = 0\n",
    "vmin = yref[::plt_step,:,:,:,component].min()\n",
    "vmax = yref[::plt_step,:,:,:,component].max()\n",
    "ylims = [inns[:,:,z_plane].min(), inns[:,:,z_plane].max()]\n",
    "fig, axes = plt.subplots(3,5,figsize=(12,6),height_ratios=(0.4,0.4,0.2))\n",
    "fig.suptitle(f'Ref, prediction and inlet pressure on observed plane z={z_plane}')\n",
    "for i in range(5):\n",
    "    axes[0,i].imshow(yref[i*plt_step,:,:,0,component].T, vmin=vmin, vmax=vmax)\n",
    "    axes[0,i].set(xlabel='x', ylabel='y')\n",
    "    axes[1,i].imshow(pred_slice[i*plt_step,:,:,0,component].T, vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='x', ylabel='y')\n",
    "    axes[2,i].plot(inns[i*plt_step,:,z_plane])\n",
    "    axes[2,i].set(xlabel=f'y at x=0 t={i*plt_step}',ylim=ylims)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test on volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl1_pred_overz = jax.vmap(mdl1.predict, (None,2), 2)\n",
    "predv1 = mdl1_pred_overz(best_state1.params, inns).reshape((*yref.shape,-1))\n",
    "predv1 = np.einsum('txyiuz -> txyzu', predv1)\n",
    "print(f'volume mse {losses.mse(predv1,u_p[...,:-1])}, measured plane {losses.mse(predv1[:,:,:,z_plane,:],yref[:,:,:,0,:])}')\n",
    "print(f'volume relative loss {losses.relative_error(predv1,u_p[...,:-1])}, measured plane {losses.relative_error(predv1[:,:,:,z_plane,:],yref[:,:,:,0,:])}')\n",
    "for r in [10,20,30]:\n",
    "    print(f'volume relative loss for planes z_plane+-{r} {losses.relative_error(predv1[...,z_plane-r:z_plane+r,:],u_p[...,z_plane-r:z_plane+r,:-1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_z = [10,25,30,34,42,60]\n",
    "plt_t = 100\n",
    "component = 0\n",
    "vmin = u_p[::plt_step,:,:,plt_z,component].min()\n",
    "vmax = u_p[::plt_step,:,:,plt_z,component].max()\n",
    "ylims = [inns[:,:,plt_z].min(), inns[:,:,plt_z].max()]\n",
    "fig, axes = plt.subplots(3,5,figsize=(12,6),height_ratios=(0.4,0.4,0.2))\n",
    "fig.suptitle('Ref, prediction and inlet pressure')\n",
    "for i in range(5):\n",
    "    axes[0,i].imshow(u_p[plt_t,:,:,plt_z[i],component].T, vmin=vmin, vmax=vmax)\n",
    "    axes[0,i].set(xlabel='x', ylabel='y')\n",
    "    axes[1,i].imshow(predv1[plt_t,:,:,plt_z[i],component].T, vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='x', ylabel='y')\n",
    "    axes[2,i].plot(inns[plt_t,:,plt_z[i]])\n",
    "    axes[2,i].set(xlabel=f'y at x=0 t={plt_t}, z={plt_z[i]}',ylim=ylims)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_t = 150\n",
    "fig,axes = plt.subplots(2,3,sharex=True,sharey=True,figsize=(5,2.5))\n",
    "fig.suptitle(f'At z={z_plane}, t={plt_t}')\n",
    "for i in range(3):\n",
    "    imref = axes[0,i].imshow(u_p[plt_t,:,:,z_plane,i].T)\n",
    "    vmin,vmax = imref.get_clim()\n",
    "    axes[1,i].imshow(predv1[plt_t,:,:,z_plane,i].T, vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='x')\n",
    "axes[0,0].set_ylabel('y')\n",
    "axes[1,0].set_ylabel('y')\n",
    "\n",
    "fig,axes = plt.subplots(2,3,sharex=True,sharey=True,figsize=(5,2.5))\n",
    "fig.suptitle(f'At x={0}, t={plt_t}')\n",
    "for i in range(3):\n",
    "    imref = axes[0,i].imshow(u_p[plt_t,0,:,:,i])\n",
    "    vmin,vmax = imref.get_clim()\n",
    "    axes[1,i].imshow(predv1[plt_t,0,:,:,i], vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='z')\n",
    "axes[0,0].set_ylabel('z')\n",
    "axes[1,0].set_ylabel('y')\n",
    "\n",
    "fig,axes = plt.subplots(2,3,sharex=True,sharey=True,figsize=(5,2.5))\n",
    "fig.suptitle(f'At z={z_plane}, time average')\n",
    "for i in range(3):\n",
    "    imref = axes[0,i].imshow(np.mean(u_p[:,:,:,z_plane,i],axis=0).T)\n",
    "    vmin,vmax = imref.get_clim()\n",
    "    axes[1,i].imshow(np.mean(predv1[:,:,:,z_plane,i],axis=0).T, vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='x')\n",
    "axes[0,0].set_ylabel('y')\n",
    "axes[1,0].set_ylabel('y')\n",
    "\n",
    "fig,axes = plt.subplots(2,3,sharex=True,sharey=True,figsize=(5,2.5))\n",
    "fig.suptitle(f'At x={0}, time average')\n",
    "for i in range(3):\n",
    "    imref = axes[0,i].imshow(np.mean(u_p[:,0,:,:,i],axis=0))\n",
    "    vmin,vmax = imref.get_clim()\n",
    "    axes[1,i].imshow(np.mean(predv1[:,0,:,:,i],axis=0), vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='z')\n",
    "axes[0,0].set_ylabel('z')\n",
    "axes[1,0].set_ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics over volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stats(pred, true):\n",
    "    fig1 = plt.figure(figsize=(4,2))\n",
    "    g = ImageGrid(fig1, 111, (1,2), cbar_mode='single')\n",
    "    imref = g.axes_all[0].imshow(np.mean(true, axis=(0,3))[:,:,0].T)\n",
    "    vmin, vmax = imref.get_clim()\n",
    "    impred = g.axes_all[1].imshow(np.mean(pred, axis=(0,3))[:,:,0].T, vmin=vmin, vmax=vmax)\n",
    "    g.cbar_axes[0].colorbar(imref)\n",
    "    fig1.suptitle('ref and reconstructed averaged over z & time')\n",
    "\n",
    "    fig2, axes = plt.subplots(1,4,figsize=(8,2))\n",
    "    for i,ax in enumerate(axes[:3]):\n",
    "        counts_true,bins_true = np.histogram(true[...,i].flatten()-np.mean(true[...,i].flatten()), density=True, bins='auto')\n",
    "        ax.stairs(counts_true,bins_true,label='true',linewidth=3, color='#808080',alpha=0.5)\n",
    "        counts,bins= np.histogram(pred[...,i].flatten()-np.mean(pred[...,i].flatten()), density=True, bins='auto')\n",
    "        ax.stairs(counts,bins,label='recons')\n",
    "    spectrum_true, kbins = derivatives.get_tke(true-np.mean(true,axis=0), datainfo)\n",
    "    spectrum, _ = derivatives.get_tke(pred-np.mean(pred,axis=0), datainfo)\n",
    "    axes[3].loglog(kbins,spectrum_true,label='true',linewidth=3, color='#808080',alpha=0.5)\n",
    "    axes[3].loglog(kbins,spectrum,label='recons')\n",
    "    axes[3].grid(which='both',axis='x')\n",
    "    axes[3].legend()\n",
    "    \n",
    "    return (fig1,g), (fig2,axes)\n",
    "\n",
    "def print_losses(pred, true):\n",
    "    with jax.default_device(jax.devices('cpu')[0]):\n",
    "        _momfield = [losses.momentum_residual_field(pred[i*80:(i+1)*80,...],datainfo,forcing=forcing) for i in range(10)]\n",
    "        _momfield = jnp.concatenate(_momfield, axis=0)\n",
    "        _momfield_ref = [losses.momentum_residual_field(true[i*80:(i+1)*80,...],datainfo,forcing=forcing) for i in range(10)]\n",
    "        _momfield_ref = jnp.concatenate(_momfield_ref, axis=0)\n",
    "        l_momentum = losses.mse(_momfield)\n",
    "        l_momentum_ref = losses.mse(_momfield_ref)\n",
    "    l_div = losses.divergence(pred[...,:-1],datainfo)\n",
    "    l_div_ref = losses.divergence(true[...,:-1],datainfo)\n",
    "    l_rel = losses.relative_error(pred, true)\n",
    "    l_mse_slice = losses.mse(pred[...,z_plane,:-1],true[...,z_plane,:-1])\n",
    "\n",
    "    print(f'ref momentum loss: {l_momentum_ref:.5f}, ref divergence loss: {l_div_ref:.5f}')\n",
    "    print(f'pred momentum loss: {l_momentum:.5f}, pred divergence loss: {l_div:.5f}')\n",
    "    print(f'Relative error of the domain {l_rel*100:.3f}%')\n",
    "    print(f'Relative error of the domain close to the measured plane from z=20 to z=50 {100*losses.relative_error(pred[...,20:50,:], true[...,20:50,:]):.5f}%')\n",
    "    print(f'MSE of the domain close to the measured plane from z=20 to z=50 {100*losses.mse(pred[...,20:50,:], true[...,20:50,:]):.5f}')\n",
    "    print(f'MSE of the measured plane {l_mse_slice:5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fig1,_), (fig2,_) = plot_stats(predv1, u_p[...,:-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Slice3D(hk.Module):\n",
    "    '''2D network trained on 3D data.'''\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            pretrained_model: hk.Module, # model\n",
    "            newvar_model:hk.Module,\n",
    "            pretrained_config = {}, \n",
    "            newvar_config = {},\n",
    "            reduce_layers = [], #int for linear\n",
    "            map_axis = (2,3), # map which input axis to which output axis  \n",
    "            pretrain_shape = (64,64,3),\n",
    "            newvar_shape = (64,64,1),\n",
    "            activation=jax.nn.tanh,\n",
    "            name = 'slice3d',\n",
    "    ):\n",
    "        super().__init__(name=name)\n",
    "        self.pretrain_mdl = pretrained_model(**pretrained_config) # this is the pre-trained one\n",
    "        self.newvar_mdl = newvar_model(**newvar_config) # this is the pre-trained one\n",
    "        self.act = activation\n",
    "        self.map_axis = map_axis\n",
    "        self.pretrain_shape = pretrain_shape\n",
    "        self.newvar_shape = newvar_shape\n",
    "        \n",
    "        self.reduce_layers = [hk.Linear(n, name=f'reduce{i}') for i,n in enumerate(reduce_layers)]\n",
    "        self.merge_layer = hk.Linear(reduce_layers[-1], name=f'merge')\n",
    "\n",
    "    def __call__(self, x, training=True):\n",
    "        \n",
    "        def over_axis(x1,training):\n",
    "            out1 = self.pretrain_mdl(x1, training=training)\n",
    "            out1_reduce = jnp.copy(out1)\n",
    "            for l in self.reduce_layers:\n",
    "                out1_reduce = self.act(out1_reduce)\n",
    "                out1_reduce = l(out1_reduce)\n",
    "            out2 = self.merge_layer(x1)\n",
    "            out2 = out2 + out1_reduce\n",
    "            print(out2.shape)\n",
    "            out2 = self.newvar_mdl(out2, training=training)\n",
    "            print(out2.shape)\n",
    "            out1 = out1.reshape((-1,) + self.pretrain_shape)\n",
    "            out2 = out2.reshape((-1,) + self.newvar_shape)\n",
    "            return jnp.concatenate((out1,out2), axis=-1)\n",
    "        \n",
    "        out = jax.vmap(over_axis, (self.map_axis[0],None), self.map_axis[1])(x, training)\n",
    "        return out\n",
    "\n",
    "    # @staticmethod\n",
    "    # def dropout(x, training:bool, dropout_rate:Optional[float]):\n",
    "    #     \"\"\"Apply dropout with if training is True\"\"\"\n",
    "    #     if training and (dropout_rate is not None):\n",
    "    #         logger.debug('Doing dropout')\n",
    "    #         return hk.dropout(hk.next_rng_key(), dropout_rate, x)\n",
    "    #     else:\n",
    "    #         return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flowrec.models.cnn import MLPWithCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_test(x,training=True):\n",
    "    mdl = Slice3D(\n",
    "            pretrained_model = MLP, # model\n",
    "            newvar_model = MLPWithCNN,\n",
    "            pretrained_config = {\n",
    "                'output_sizes':[128,256,1024,yref[0,...].size],\n",
    "                'name': 'mdl1',\n",
    "                'w_init':hk.initializers.VarianceScaling(1.0),\n",
    "                'activation':jax.nn.tanh\n",
    "            }, \n",
    "            # newvar_config = {\n",
    "            #     'output_sizes':[256,1024,int(yref[0,...].size/3)],\n",
    "            #     'name': 'mdl2',\n",
    "            #     'w_init':hk.initializers.VarianceScaling(1.0),\n",
    "            #     'activation':jax.nn.tanh\n",
    "            # },\n",
    "            newvar_config = {\n",
    "                'mlp_layers': [256,1024,4096],\n",
    "                'output_shape': (64,64,1), \n",
    "                'cnn_channels': [2,2,1],\n",
    "                'cnn_filters': [(3,3)]\n",
    "            },\n",
    "            reduce_layers = [10,100], #int for linear\n",
    "            map_axis = (2,3), # map which input axis to which output axis  \n",
    "    )\n",
    "    return mdl(x, training)\n",
    "\n",
    "mdl_test = hk.transform(forward_test)\n",
    "test_params = mdl_test.init(key, inns[:10,:,30:35])\n",
    "print(list(test_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_apply = jax.jit(mdl_test.apply, static_argnames=['training'])\n",
    "test_out = jit_apply(test_params, key, inns[:10, :, 30:32], training=False)\n",
    "print(test_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_state1.params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward2(p):\n",
    "    _mlp = MLP(\n",
    "        [128,256,1024,yref[0,...].size],\n",
    "        name = 'mdl1',\n",
    "        w_init=hk.initializers.VarianceScaling(1.0),\n",
    "        activation=jax.nn.tanh\n",
    "    )\n",
    "    imagesize = yref.shape[1:-2]\n",
    "    linear_reduce = [hk.Linear(n, name=f'reduce{i}') for i,n in enumerate([512,128])]\n",
    "    linear_p = [hk.Linear(n, name=f'p{i}') for i,n in enumerate([128,512,1024,int(yref[0,...].size/3)])]\n",
    "    def over_z(p1):\n",
    "        u = _mlp(p1,TRAINING=True)\n",
    "        u_reduce = jnp.copy(u)\n",
    "        for l in linear_reduce:\n",
    "            u_reduce = jax.nn.tanh(u_reduce)\n",
    "            u_reduce = l(u_reduce)\n",
    "        outp = linear_p[0](p1)\n",
    "        outp = outp + u_reduce\n",
    "        for l in linear_p[1:]:\n",
    "            outp = jax.nn.tanh(outp)\n",
    "            outp = l(outp)\n",
    "        outp = outp.reshape((-1,)+imagesize+(1,))\n",
    "        return jnp.concatenate((u.reshape((-1,)+imagesize+(3,)), outp), axis=-1) # (txy1u)\n",
    "    out = jax.vmap(over_z, 2, 3)(p)\n",
    "    return out\n",
    "mdl2 = hk.transform(forward2)\n",
    "params2 = mdl2.init(key, inns[:10,:,30:35])\n",
    "print(list(params2))\n",
    "print(mdl2.apply(params2, None, inns[:10,:,30:35]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split weights\n",
    "for k, layer in best_state1.params.items():\n",
    "    if k in params2.keys():\n",
    "        params2[k].update(layer)\n",
    "        # print(k, layer.keys())\n",
    "print(np.allclose(params2['mdl1/~/linear_3']['w'], best_state1.params['mdl1/~/linear_3']['w']))\n",
    "params2_non_trainable, params2_trainable = hk.data_structures.partition(\n",
    "    lambda module_name, name, value: module_name in ['mdl1/~/linear_0', 'mdl1/~/linear_1', 'mdl1/~/linear_2','mdl1/~/linear_3'],\n",
    "    params2\n",
    ")\n",
    "print(list(params2_trainable))\n",
    "print(list(params2_non_trainable))\n",
    "# print(jax.tree_map(lambda x: print(x.shape),params2_trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "scheduler2 = optimiser_options.get_scheduler('exponential_decay', lr)\n",
    "optimiser2 = optax.adamw(learning_rate=scheduler2)\n",
    "opt_state2 = optimiser2.init(params2_trainable)\n",
    "state2 = train.TrainingState(params=params2_trainable, opt_state=opt_state2)\n",
    "print(mdl2.apply(\n",
    "    hk.data_structures.merge(state2.params,params2_non_trainable),\n",
    "    key, \n",
    "    inns[:10,...]\n",
    ").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss2(apply_fn, trainable, rng, inns, yall, non_trainable, forcing, z_plane, w_ld):\n",
    "    params = hk.data_structures.merge(trainable, non_trainable)\n",
    "    pred = apply_fn(params, rng, inns)\n",
    "    print(pred.shape)\n",
    "    ld = losses.mse(pred[:,:,:,z_plane,:-1], yall[:,:,:,z_plane,:-1]) + losses.mse(pred[inns_loc],yall[inns_loc]) # data loss, velocities on the plane and pressure at inlet\n",
    "    pred_new = pred.at[:,:,:,z_plane,:-1].set(yall[:,:,:,z_plane,:-1])\n",
    "    pred_new = pred_new.at[inns_loc].set(yall[inns_loc])\n",
    "    # unnormalise before taking physics loss\n",
    "    ldiv = losses.divergence(pred_new[...,:-1], datainfo)\n",
    "    lmom = losses.momentum_loss(pred_new, datainfo, forcing=forcing)\n",
    "    # Poisson equation for incompressible flow\n",
    "    # lp = \n",
    "    \n",
    "    return w_ld*ld + ldiv + lmom, {'plane': ld, 'div':ldiv, 'momentum':lmom}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## z_plane must change if not training with all slices\n",
    "z1,z2 = 20,50\n",
    "update2 = train.generate_update_fn(\n",
    "    mdl2.apply,\n",
    "    optimiser2,\n",
    "    loss2,\n",
    "    kwargs_loss={'non_trainable': params2_non_trainable, 'forcing': forcing[...,[0]], 'z_plane':z_plane-z1, 'w_ld':50},\n",
    "    kwargs_value_and_grad={'has_aux':True}\n",
    ")\n",
    "l,_ = update2(state2, key, inns[:20,...,z1:z2], u_p[:20,...,z1:z2,:])\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predv2 = mdl2.apply(params2, None, inns[:200,...])\n",
    "plt_zgap = 10\n",
    "plt_t = 100\n",
    "vmin = u_p[plt_t,...,::plt_zgap,0].min()\n",
    "vmax = u_p[plt_t,...,::plt_zgap,0].max()\n",
    "fig,axes = plt.subplots(3,6,figsize=(15,6),height_ratios=(0.4,0.4,0.2))\n",
    "fig.suptitle(f'mdl2 after loading the weights from mdl1. Trained on z={z_plane}')\n",
    "for i in range(6):\n",
    "    axes[2,i].plot(inns[plt_t,:,i*plt_zgap])\n",
    "    axes[2,i].set(xlabel=f'y at z={i*plt_zgap}, t={plt_t}', ylim=[inns[plt_t,:,::plt_zgap].min(), inns[plt_t,:,::plt_zgap].max()])\n",
    "    axes[0,i].imshow(u_p[plt_t,:,:,i*plt_zgap,0].T, vmin=vmin, vmax=vmax)\n",
    "    axes[0,i].set(xlabel='x')\n",
    "    axes[1,i].imshow(predv2[plt_t,:,:,i*plt_zgap,0].T, vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='x')\n",
    "axes[0,0].set_ylabel('y')\n",
    "axes[1,0].set_ylabel('y')\n",
    "axes[2,0].set_ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2 = {'loss':[], 'plane':[], 'div':[], 'momentum':[]}\n",
    "best_l = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 300\n",
    "batch = 500\n",
    "for i in range(n_epochs):\n",
    "    [key] = jax.random.split(key,1)\n",
    "    l_epoch = {'loss':[], 'div':[], 'plane':[], 'momentum':[]}\n",
    "    j = 0\n",
    "    while (j+1)*batch <=  u_p.shape[0]:\n",
    "        (_l, _l_components), state2 = update2(state2, key, inns[j*batch:(j+1)*batch,...,z1:z2], u_p[j*batch:(j+1)*batch,...,z1:z2,:])\n",
    "        j += 1\n",
    "        l_epoch['loss'].append(float(_l))\n",
    "        for k,a in _l_components.items():\n",
    "            l_epoch[k].append(float(a))\n",
    "    for k,a in l_epoch.items():\n",
    "        hist2[k].append(np.mean(a))\n",
    "    if i % 20 == 0:\n",
    "        print(f'epoch {i}, ', \" \".join(f\"{k}: {a[-1]:.5f}\" for k, a in hist2.items()))\n",
    "    if hist2['loss'][-1] < best_l:\n",
    "        best_state2 = state2\n",
    "        best_l = hist2['loss'][-1]\n",
    "plt.figure(figsize=(5,3))\n",
    "for k in hist2.keys():\n",
    "    plt.semilogy(hist2[k], label=k)\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss mse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predv2 = mdl2.apply(hk.data_structures.merge(best_state2.params, params2_non_trainable), None, inns[:200,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_zgap = 10\n",
    "plt_t = 150\n",
    "vmin = u_p[plt_t,...,::plt_zgap,0].min()\n",
    "vmax = u_p[plt_t,...,::plt_zgap,0].max()\n",
    "vminp = u_p[plt_t,...,::plt_zgap,-1].min()\n",
    "vmaxp = u_p[plt_t,...,::plt_zgap,-1].max()\n",
    "fig,axes = plt.subplots(5,6,figsize=(15,9),height_ratios=(0.21,0.21,0.21,0.21,0.1))\n",
    "fig.suptitle(f'mdl2. Top 2: ref and pred u1, bottom 2: red and pred p. Trained using slices z={z1} to {z2}.')\n",
    "for i in range(6):\n",
    "    axes[4,i].plot(inns[plt_t,:,i*plt_zgap])\n",
    "    axes[4,i].plot(predv2[inns_loc][plt_t,:,i*plt_zgap],'--')\n",
    "    axes[4,i].set(xlabel=f'y at z={i*plt_zgap}, t={plt_t}', ylim=[inns[plt_t,:,::plt_zgap].min(), inns[plt_t,:,::plt_zgap].max()])\n",
    "    axes[0,i].imshow(u_p[plt_t,:,:,i*plt_zgap,0].T, vmin=vmin, vmax=vmax)\n",
    "    axes[0,i].set(xlabel='x')\n",
    "    axes[1,i].imshow(predv2[plt_t,:,:,i*plt_zgap,0].T, vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='x')\n",
    "    axes[2,i].imshow(u_p[plt_t,:,:,i*plt_zgap,-1].T, vmin=vminp, vmax=vmaxp)\n",
    "    axes[2,i].set(xlabel='x')\n",
    "    axes[3,i].imshow(predv2[plt_t,:,:,i*plt_zgap,-1].T, vmin=vminp, vmax=vmaxp)\n",
    "    axes[3,i].set(xlabel='x')\n",
    "axes[0,0].set_ylabel('y')\n",
    "axes[1,0].set_ylabel('y')\n",
    "axes[2,0].set_ylabel('y')\n",
    "axes[3,0].set_ylabel('y')\n",
    "axes[4,0].set_ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stats(predv2, u_p[...,:-1])\n",
    "plt.figure(figsize=(2,2))\n",
    "counts_true,bins_true = np.histogram(u_p[...,-1].flatten()-np.mean(u_p[...,0].flatten()), density=True, bins='auto')\n",
    "plt.stairs(counts_true,bins_true,label='true',linewidth=3, color='#808080',alpha=0.5)\n",
    "counts_pred,bins_pred = np.histogram(predv2[...,-1].flatten()-np.mean(predv2[...,0].flatten()), density=True, bins='auto')\n",
    "plt.stairs(counts_pred,bins_pred,label='recons')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine tune last layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2v2_trainable, params2v2_non_trainable = hk.data_structures.partition(\n",
    "    lambda module_name, name, value: module_name in ['mdl1/~/linear_1','mdl1/~/linear_2','mdl1/~/linear_3','p3','p2','reduce1','reduce0'],\n",
    "    hk.data_structures.merge(best_state2.params, params2_non_trainable)\n",
    ")\n",
    "print(list(params2v2_trainable))\n",
    "print(list(params2v2_non_trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2v2_non_trainable, params2v2_trainable = hk.data_structures.partition(\n",
    "    lambda module_name, name, value: module_name in ['mdl1/~/linear_0','mdl1/~/linear_1'],\n",
    "    params2\n",
    ")\n",
    "print(list(params2v2_trainable))\n",
    "print(list(params2v2_non_trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in hk.data_structures.merge(params2v2_trainable, params2v2_non_trainable).items():\n",
    "    print(np.allclose(v['w'],hk.data_structures.merge(best_state2.params, params2_non_trainable)[k]['w']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predv2_2pretrain = mdl2.apply(hk.data_structures.merge(params2v2_trainable, params2v2_non_trainable), None, inns[:200,...])\n",
    "plt_zgap = 12\n",
    "plt_t = 150\n",
    "vmin = u_p[plt_t,...,::plt_zgap,0].min()\n",
    "vmax = u_p[plt_t,...,::plt_zgap,0].max()\n",
    "vminp = u_p[plt_t,...,::plt_zgap,-1].min()\n",
    "vmaxp = u_p[plt_t,...,::plt_zgap,-1].max()\n",
    "fig,axes = plt.subplots(5,6,figsize=(15,9),height_ratios=(0.21,0.21,0.21,0.21,0.1))\n",
    "fig.suptitle(f'mdl2 pre-training. Top 2: ref and pred u1, bottom 2: red and pred p. Trained on z={z1} to {z2}.')\n",
    "for i in range(6):\n",
    "    axes[4,i].plot(inns[plt_t,:,i*plt_zgap])\n",
    "    axes[4,i].plot(predv2_2pretrain[inns_loc][plt_t,:,i*plt_zgap],'--')\n",
    "    axes[4,i].set(xlabel=f'y at z={i*plt_zgap}, t={plt_t}', ylim=[inns[plt_t,:,::plt_zgap].min(), inns[plt_t,:,::plt_zgap].max()])\n",
    "    axes[0,i].imshow(u_p[plt_t,:,:,i*plt_zgap,0].T, vmin=vmin, vmax=vmax)\n",
    "    axes[0,i].set(xlabel='x')\n",
    "    axes[1,i].imshow(predv2_2pretrain[plt_t,:,:,i*plt_zgap,0].T, vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='x')\n",
    "    axes[2,i].imshow(u_p[plt_t,:,:,i*plt_zgap,-1].T, vmin=vminp, vmax=vmaxp)\n",
    "    axes[2,i].set(xlabel='x')\n",
    "    axes[3,i].imshow(predv2_2pretrain[plt_t,:,:,i*plt_zgap,-1].T, vmin=vminp, vmax=vmaxp)\n",
    "    axes[3,i].set(xlabel='x')\n",
    "axes[0,0].set_ylabel('y')\n",
    "axes[1,0].set_ylabel('y')\n",
    "axes[2,0].set_ylabel('y')\n",
    "axes[3,0].set_ylabel('y')\n",
    "axes[4,0].set_ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "scheduler2v2 = optimiser_options.get_scheduler('cyclic_decay_default', lr)\n",
    "optimiser2v2 = optax.adamw(learning_rate=scheduler2v2)\n",
    "opt_state2v2 = optimiser2v2.init(params2v2_trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in best_state1.opt_state[0].mu.items():\n",
    "    if k in opt_state2v2[0].mu.keys():\n",
    "        opt_state2v2[0].mu.update({k: v})\n",
    "for k,v in best_state1.opt_state[0].nu.items():\n",
    "    if k in opt_state2v2[0].nu.keys():\n",
    "        opt_state2v2[0].nu.update({k: v})\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state2v2 = train.TrainingState(params=params2v2_trainable, opt_state=opt_state2v2)\n",
    "print(mdl2.apply(\n",
    "    hk.data_structures.merge(state2v2.params,params2v2_non_trainable),\n",
    "    key, \n",
    "    inns[:10,...]\n",
    ").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## z_plane must change if not training with all slices\n",
    "z1,z2 = 20,50\n",
    "update2v2 = train.generate_update_fn(\n",
    "    mdl2.apply,\n",
    "    optimiser2v2,\n",
    "    loss2,\n",
    "    kwargs_loss={'non_trainable': params2v2_non_trainable, 'forcing': forcing[...,[0]], 'z_plane':z_plane-z1, 'w_ld':80},\n",
    "    kwargs_value_and_grad={'has_aux':True}\n",
    ")\n",
    "l,_ = update2v2(state2v2, key, inns[:20,...,z1:z2], u_p[:20,...,z1:z2,:])\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2v2 = {'loss':[], 'plane':[], 'div':[], 'momentum':[]}\n",
    "best_l = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batch = 500\n",
    "for i in range(n_epochs):\n",
    "    [key] = jax.random.split(key,1)\n",
    "    l_epoch = {'loss':[], 'div':[], 'plane':[], 'momentum':[]}\n",
    "    j = 0\n",
    "    while (j+1)*batch <=  u_p.shape[0]:\n",
    "        (_l, _l_components), state2v2 = update2v2(state2v2, key, inns[j*batch:(j+1)*batch,...,z1:z2], u_p[j*batch:(j+1)*batch,...,z1:z2,:])\n",
    "        j += 1\n",
    "        l_epoch['loss'].append(float(_l))\n",
    "        for k,a in _l_components.items():\n",
    "            l_epoch[k].append(float(a))\n",
    "    for k,a in l_epoch.items():\n",
    "        hist2v2[k].append(np.mean(a))\n",
    "    if i % 20 == 0:\n",
    "        print(f'epoch {i}, ', \" \".join(f\"{k}: {a[-1]:.5f}\" for k, a in hist2v2.items()))\n",
    "    if hist2v2['loss'][-1] < best_l:\n",
    "        best_state2v2 = state2v2\n",
    "        best_l = hist2v2['loss'][-1]\n",
    "plt.figure(figsize=(5,3))\n",
    "for k in hist2v2.keys():\n",
    "    plt.semilogy(hist2v2[k], label=k)\n",
    "plt.legend() \n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss mse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "predv2_2 = [mdl2.apply(hk.data_structures.merge(best_state2v2.params, params2v2_non_trainable), None, inns[i*200:(i+1)*200,...]) for i in range(4)]\n",
    "predv2_2 = np.concatenate(predv2_2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt_zgap = 10\n",
    "# plt_t = 150\n",
    "vmin = u_p[plt_t,...,::plt_zgap,0].min()\n",
    "vmax = u_p[plt_t,...,::plt_zgap,0].max()\n",
    "vminp = u_p[plt_t,...,::plt_zgap,-1].min()\n",
    "vmaxp = u_p[plt_t,...,::plt_zgap,-1].max()\n",
    "fig,axes = plt.subplots(7,6,figsize=(15,15),height_ratios=(0.15,0.15,0.15,0.15,0.15,0.15,0.1))\n",
    "fig.suptitle(f'mdl2v2 fine tuning. Top 2: ref and pred u1, bottom 2: red and pred p. Trained on z={z1} to {z2}.')\n",
    "for i in range(6):\n",
    "    axes[6,i].plot(inns[plt_t,:,i*plt_zgap])\n",
    "    axes[6,i].plot(predv2_2[inns_loc][plt_t,:,i*plt_zgap],'--')\n",
    "    axes[6,i].set(xlabel=f'y at z={i*plt_zgap}, t={plt_t}', ylim=[inns[plt_t,:,::plt_zgap].min(), inns[plt_t,:,::plt_zgap].max()])\n",
    "    \n",
    "    axes[0,i].imshow(u_p[plt_t,:,:,i*plt_zgap,0].T, vmin=vmin, vmax=vmax)\n",
    "    axes[0,i].set(xlabel='x')\n",
    "    axes[1,i].imshow(predv2_2[plt_t,:,:,i*plt_zgap,0].T, vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='x')\n",
    "    axes[2,i].imshow(np.abs(u_p[plt_t,:,:,i*plt_zgap,0].T-predv2_2[plt_t,:,:,i*plt_zgap,0].T))\n",
    "    axes[2,i].set(xlabel='x')\n",
    "\n",
    "    axes[3,i].imshow(u_p[plt_t,:,:,i*plt_zgap,-1].T, vmin=vminp, vmax=vmaxp)\n",
    "    axes[3,i].set(xlabel='x')\n",
    "    axes[4,i].imshow(predv2_2[plt_t,:,:,i*plt_zgap,-1].T, vmin=vminp, vmax=vmaxp)\n",
    "    axes[4,i].set(xlabel='x')\n",
    "    axes[5,i].imshow(np.abs(u_p[plt_t,:,:,i*plt_zgap,-1].T-predv2_2[plt_t,:,:,i*plt_zgap,-1].T))\n",
    "    axes[5,i].set(xlabel='x')\n",
    "\n",
    "axes[0,0].set_ylabel('y')\n",
    "axes[1,0].set_ylabel('y')\n",
    "axes[2,0].set_ylabel('y')\n",
    "axes[3,0].set_ylabel('y')\n",
    "axes[4,0].set_ylabel('y')\n",
    "axes[5,0].set_ylabel('y')\n",
    "axes[6,0].set_ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2,4,sharex=True,sharey=True,figsize=(5,2.5))\n",
    "fig.suptitle(f'At z={z_plane}, t={plt_t}')\n",
    "for i in range(4):\n",
    "    imref = axes[0,i].imshow(u_p[plt_t,:,:,z_plane,i].T)\n",
    "    vmin,vmax = imref.get_clim()\n",
    "    axes[1,i].imshow(predv2_2[plt_t,:,:,z_plane,i].T, vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='x')\n",
    "axes[0,0].set_ylabel('y')\n",
    "axes[1,0].set_ylabel('y')\n",
    "\n",
    "fig,axes = plt.subplots(2,4,sharex=True,sharey=True,figsize=(5,2.5))\n",
    "fig.suptitle(f'At x={0}, t={plt_t}')\n",
    "for i in range(4):\n",
    "    imref = axes[0,i].imshow(u_p[plt_t,0,:,:,i])\n",
    "    vmin,vmax = imref.get_clim()\n",
    "    axes[1,i].imshow(predv2_2[plt_t,0,:,:,i], vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='z')\n",
    "axes[0,0].set_ylabel('z')\n",
    "axes[1,0].set_ylabel('y')\n",
    "\n",
    "fig,axes = plt.subplots(2,4,sharex=True,sharey=True,figsize=(5,2.5))\n",
    "fig.suptitle(f'At z={z_plane}, time average')\n",
    "for i in range(4):\n",
    "    imref = axes[0,i].imshow(np.mean(u_p[:,:,:,z_plane,i],axis=0).T)\n",
    "    vmin,vmax = imref.get_clim()\n",
    "    axes[1,i].imshow(np.mean(predv2_2[:,:,:,z_plane,i],axis=0).T, vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='x')\n",
    "axes[0,0].set_ylabel('y')\n",
    "axes[1,0].set_ylabel('y')\n",
    "\n",
    "fig,axes = plt.subplots(2,4,sharex=True,sharey=True,figsize=(5,2.5))\n",
    "fig.suptitle(f'At x={0}, time average')\n",
    "for i in range(4):\n",
    "    imref = axes[0,i].imshow(np.mean(u_p[:,0,:,:,i],axis=0))\n",
    "    vmin,vmax = imref.get_clim()\n",
    "    axes[1,i].imshow(np.mean(predv2_2[:,0,:,:,i],axis=0), vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='z')\n",
    "axes[0,0].set_ylabel('z')\n",
    "axes[1,0].set_ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fig1,_),(fig2,axes) = plot_stats(predv2_2, u_p[...,:-1])\n",
    "spectrum_pretrain, kbins = derivatives.get_tke(predv2-np.mean(predv2,axis=0), datainfo)\n",
    "axes[3].loglog(kbins, spectrum_pretrain, label='pretrain')\n",
    "k_nyquist = (2*np.pi / np.sqrt(2*(datainfo.dx**2))) / 2.\n",
    "axes[3].grid()\n",
    "axes[3].vlines(k_nyquist,10**-13, 10**8, 'k')\n",
    "# axes[3].set_xlim([0.1, k_nyquist])\n",
    "axes[3].legend()\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "counts_true,bins_true = np.histogram(u_p[...,-1].flatten()-np.mean(u_p[...,0].flatten()), density=True, bins='auto')\n",
    "plt.stairs(counts_true,bins_true,label='true',linewidth=3, color='#808080',alpha=0.5)\n",
    "counts_pred, bins_pred = np.histogram(predv2_2[...,-1].flatten()-np.mean(predv2[...,0].flatten()), density=True, bins='auto')\n",
    "plt.stairs(counts_pred,bins_pred,label='recons')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print_losses(predv2_2, u_p[:predv2_2.shape[0],...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High frequency content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chose cut off frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fftfreq = jnp.fft.fftfreq(64,datainfo.dx)*2*np.pi\n",
    "rfftfreq = jnp.fft.rfftfreq(64,datainfo.dx)*2*np.pi\n",
    "fe_plane = jnp.fft.rfftn(u_p[...,z_plane,:]-jnp.mean(u_p[...,z_plane,:],axis=0),axes=[1,2])\n",
    "fe_pred = jnp.fft.rfftn(predv2_2[...,z_plane,:]-jnp.mean(predv2_2[...,z_plane,:],axis=0),axes=[1,2])\n",
    "print(fe_plane.shape)\n",
    "print(k_nyquist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "kgrid = np.array(np.meshgrid(fftfreq,rfftfreq,indexing='ij'))\n",
    "kgrid_magnitude = np.sqrt(np.einsum('n... -> ...', kgrid**2))\n",
    "highpass = kgrid_magnitude > 7.\n",
    "lowpass = ~ highpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2,4,figsize=(9,3),sharex='all',sharey='all')\n",
    "for i in range(4):\n",
    "    im0 = axes[0,i].imshow(np.sum(np.abs(fe_plane[:,:33,:,i]),axis=0),extent=(0,fftfreq.max(),0,fftfreq.max()),norm=LogNorm())\n",
    "    axes[0,i].imshow(np.zeros_like(lowpass[:33,:33]),alpha=lowpass[:33,:33]*0.3,origin='lower',extent=(0,fftfreq.max(),0,fftfreq.max()))\n",
    "    plt.colorbar(im0,ax=axes[0,i])\n",
    "    im1 = axes[1,i].imshow(np.sum(np.abs(fe_pred[:,:33,:,i]),axis=0),extent=(0,fftfreq.max(),0,fftfreq.max()),norm=LogNorm())\n",
    "    plt.colorbar(im1,ax=axes[1,i])\n",
    "    axes[1,i].imshow(np.zeros_like(lowpass[:33,:33]),alpha=lowpass[:33,:33]*0.3,origin='lower',extent=(0,fftfreq.max(),0,fftfreq.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lowpass filter\n",
    "refplane_lowpass = jnp.fft.irfft2(fe_plane*lowpass[jnp.newaxis,:,:,jnp.newaxis],axes=[1,2])\n",
    "predv2_2plane_lowpass = jnp.fft.irfft2(fe_pred*lowpass[jnp.newaxis,:,:,jnp.newaxis],axes=[1,2])\n",
    "refplane_highpass = jnp.fft.irfft2(fe_plane*highpass[jnp.newaxis,:,:,jnp.newaxis],axes=[1,2])\n",
    "predv2_2plane_highpass = jnp.fft.irfft2(fe_pred*highpass[jnp.newaxis,:,:,jnp.newaxis],axes=[1,2])\n",
    "fig,axes = plt.subplots(2,3,figsize=(6,4))\n",
    "fig.suptitle('u1 fluc')\n",
    "axes[0,0].imshow(u_p[100,:,:,z_plane,0]-jnp.mean(u_p[...,z_plane,0],axis=0))\n",
    "axes[0,0].set_title('ref')\n",
    "axes[0,1].imshow(refplane_lowpass[100,:,:,0])\n",
    "axes[0,1].set_title('ref low pass')\n",
    "axes[0,2].imshow(refplane_highpass[100,:,:,0])\n",
    "axes[0,2].set_title('ref high pass')\n",
    "axes[1,0].imshow(predv2_2[100,:,:,z_plane,0]-jnp.mean(predv2_2[...,z_plane,0],axis=0))\n",
    "axes[1,0].set_title('reconstructed')\n",
    "axes[1,1].imshow(predv2_2plane_lowpass[100,:,:,0])\n",
    "axes[1,1].set_title('reconstructed low pass')\n",
    "axes[1,2].imshow(predv2_2plane_highpass[100,:,:,0])\n",
    "axes[1,2].set_title('reconstructed high pass')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "counts,bins= np.histogram(u_p[...,z_plane,0].flatten()-np.mean(u_p[...,z_plane,0].flatten()), density=True, bins='auto')\n",
    "plt.stairs(counts,bins,label='ref')\n",
    "counts,bins= np.histogram(\n",
    "    u_p[...,z_plane,0].flatten() - np.mean(u_p[...,z_plane,0].flatten()) - refplane_lowpass[...,0].flatten(),\n",
    "    density=True, \n",
    "    bins='auto'\n",
    ")\n",
    "plt.stairs(counts,bins,label='lowpass')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(np.std(u_p[...,z_plane,0].flatten()-np.mean(u_p[...,z_plane,0].flatten())), np.std(u_p[...,z_plane,0].flatten() - np.mean(u_p[...,z_plane,0].flatten()) - refplane_lowpass[...,0].flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on high frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_resize = jax.vmap(partial(jax.image.resize,method='linear'),(-1,None),-1)\n",
    "vv_resize = jax.vmap(v_resize,(0,None),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward3(p,x_lowfreq):\n",
    "    output_shape = (-1,64,64,4)\n",
    "    # highpass = kgrid_magnitude > kcutoff\n",
    "    # lowpass = ~ highpass\n",
    "\n",
    "    linear_p = [hk.Linear(n,name=f'pin{i}') for i,n in enumerate([128,128])]\n",
    "    cnn_xin = [hk.Conv2D(n,3,name=f'cnn_xin{i}') for i,n in enumerate([4,8,16])]\n",
    "    cnn_xshape = [(32,32),(16,16),(8,8)]\n",
    "    # linear_xin = [hk.Linear(n,name=f'linear_xin{i}') for i,n in enumerate([300,256])]\n",
    "    linear_xreduce = hk.Linear(128,name='xreduce')\n",
    "    linear_xexpand = [hk.Linear(n, name=f'xexpand{i}') for i,n in enumerate([256,64*64*4])]\n",
    "    act = jax.nn.tanh\n",
    "\n",
    "    # def freq_filter(x1,filter):\n",
    "    #     fe = jnp.fft.rfftn(x1-jnp.mean(x1,axis=0), axes=[1,2])\n",
    "    #     x1_filter = jnp.fft.irfft2(fe*filter[jnp.newaxis,:,:,jnp.newaxis],axes=[1,2])\n",
    "    #     return x1_filter\n",
    "        \n",
    "    def over_z(p1,x1):\n",
    "        # x1_lowpass = freq_filter(x1,lowpass) \n",
    "        for l in linear_p:\n",
    "            p1 = l(p1)\n",
    "            p1 = act(p1)\n",
    "        # x1_reduce = jnp.reshape(x1, (x1.shape[0],-1))\n",
    "        x1_reduce = x1\n",
    "        for l,s in zip(cnn_xin,cnn_xshape):\n",
    "            x1_reduce = l(x1_reduce)\n",
    "            x1_reduce = act(x1_reduce)\n",
    "            x1_reduce = vv_resize(x1_reduce, s)\n",
    "        # for l in linear_xin:\n",
    "        #     x1 = l(x1)\n",
    "        #     x1 = act(x1)\n",
    "        x1_reduce = linear_xreduce(x1_reduce.reshape(x1.shape[0],-1))\n",
    "        x1_expand = x1_reduce + p1\n",
    "        for l in linear_xexpand:\n",
    "            x1_expand = act(x1_expand)\n",
    "            x1_expand = l(x1_expand)\n",
    "        out1 = x1_expand.reshape(output_shape)\n",
    "        return out1+ x1\n",
    "\n",
    "    out = jax.vmap(over_z, (2,3),3)(p,x_lowfreq)\n",
    "    return out\n",
    "\n",
    "mdl3 = hk.transform(forward3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss3(apply_fn, params, rng, inns, yall, forcing, z_plane):\n",
    "    pred = apply_fn(params, rng, *inns)\n",
    "    print(pred.shape)\n",
    "    ld = losses.mse(pred[:,:,:,z_plane,:-1], yall[:,:,:,z_plane,:-1]) + losses.mse(pred[inns_loc],yall[inns_loc]) # data loss, velocities on the plane and pressure at inlet\n",
    "    pred_new = pred.at[:,:,:,z_plane,:-1].set(yall[:,:,:,z_plane,:-1])\n",
    "    pred_new = pred_new.at[inns_loc].set(yall[inns_loc])\n",
    "    ldiv = losses.divergence(pred_new[...,:-1], datainfo)\n",
    "    lmom = losses.momentum_loss(pred_new, datainfo, forcing=forcing)\n",
    "    return 80*ld + ldiv + lmom, {'plane': ld, 'div':ldiv, 'momentum':lmom}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pred = [mdl2.apply(hk.data_structures.merge(best_state2v2.params,params2v2_non_trainable), None, inns[i*100:(i+1)*100,...]) for i in range(8)]\n",
    "_pred = np.concatenate(_pred, axis=0)\n",
    "_pred = np.fft.rfftn(_pred, axes=[1,2])\n",
    "fft_u_p = np.fft.rfftn(u_p, axes=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get low frequency data\n",
    "cutoff = 7.\n",
    "lowpass_filter = kgrid_magnitude < cutoff\n",
    "highpass_filter = ~lowpass_filter\n",
    "ref_lowfreq = np.fft.irfft2(fft_u_p*lowpass_filter[np.newaxis,:,:,np.newaxis,np.newaxis],axes=[1,2])\n",
    "ref_highfreq = np.fft.irfft2(fft_u_p*highpass_filter[np.newaxis,:,:,np.newaxis,np.newaxis],axes=[1,2])\n",
    "predv2_2_lowfreq  = np.fft.irfft2(_pred*lowpass_filter[np.newaxis,:,:,np.newaxis,np.newaxis],axes=[1,2])\n",
    "predv2_2_highfreq  = np.fft.irfft2(_pred*highpass_filter[np.newaxis,:,:,np.newaxis,np.newaxis],axes=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltz = 25\n",
    "fig,axes = plt.subplots(4,4,figsize=(6,6))\n",
    "for i in range(4):\n",
    "    axes[0,i].imshow(ref_lowfreq[plt_t,:,:,pltz,i].T)\n",
    "    axes[1,i].imshow(ref_highfreq[plt_t,:,:,pltz,i].T)\n",
    "    axes[2,i].imshow(predv2_2_lowfreq[plt_t,:,:,pltz,i].T)\n",
    "    axes[3,i].imshow(predv2_2_highfreq[plt_t,:,:,pltz,i].T)\n",
    "fig.suptitle(f'At t={plt_t}, z={pltz}. From top: ref low frequency, high frequency, mdlv2-2 low frequency, high frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params3 = mdl3.init(key, inns[:10,:,30:35], predv2_2[:10,:,:,30:35,:])\n",
    "print(list(params3))\n",
    "print(mdl3.apply(params3, None, inns[:10,:,30:35], predv2_2[:10,:,:,30:35,:]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "scheduler3 = optimiser_options.get_scheduler('cyclic_decay_default',lr)\n",
    "optimiser3 = optax.adamw(learning_rate=scheduler3)\n",
    "opt_state3 = optimiser3.init(params3)\n",
    "state3 = train.TrainingState(params=params3, opt_state=opt_state3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update3 = train.generate_update_fn(\n",
    "    mdl3.apply,\n",
    "    optimiser3,\n",
    "    loss3,\n",
    "    kwargs_loss={'forcing': forcing[...,[0]], 'z_plane':z_plane-z1},\n",
    "    kwargs_value_and_grad={'has_aux':True}\n",
    ")\n",
    "l, _ = update3(\n",
    "    state3, \n",
    "    key, \n",
    "    (inns[:20,...,z1:z2], predv2_2[:20,...,z1:z2,:]),\n",
    "    u_p[:20,...,z1:z2,:]\n",
    ")\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(jax.devices()[0].client.live_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist3 = {'loss':[], 'plane':[], 'div':[], 'momentum':[]}\n",
    "best_l = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 800\n",
    "batch = 100\n",
    "for i in range(n_epochs):\n",
    "    [key] = jax.random.split(key,1)\n",
    "    l_epoch = {'loss':[], 'div':[], 'plane':[], 'momentum':[]}\n",
    "    j = 0\n",
    "    while (j+1)*batch <=  u_p.shape[0]:\n",
    "        (_l, _l_components), state3 = update3(\n",
    "            state3, \n",
    "            key, \n",
    "            (inns[j*batch:(j+1)*batch,...,z1:z2], predv2_2_lowfreq[j*batch:(j+1)*batch,...,z1:z2,:]), \n",
    "            u_p[j*batch:(j+1)*batch,...,z1:z2,:]\n",
    "        )\n",
    "        j += 1\n",
    "        l_epoch['loss'].append(float(_l))\n",
    "        for k,a in _l_components.items():\n",
    "            l_epoch[k].append(float(a))\n",
    "    for k,a in l_epoch.items():\n",
    "        hist3[k].append(np.mean(a))\n",
    "    if i % 20 == 0:\n",
    "        print(f'epoch {i}, ', \" \".join(f\"{k}: {a[-1]:.5f}\" for k, a in hist3.items()))\n",
    "    if hist3['loss'][-1] < best_l:\n",
    "        best_state3 = state3\n",
    "        best_l = hist3['loss'][-1]\n",
    "plt.figure(figsize=(5,3))\n",
    "for k in hist3.keys():\n",
    "    plt.semilogy(hist3[k], label=k)\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss mse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "predv3 = [mdl3.apply(best_state3.params, None, inns[i*200:(i+1)*200,...], predv2_2_lowfreq[i*200:(i+1)*200,...]) for i in range(4)]\n",
    "predv3 = np.concatenate(predv3,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt_zgap = 10\n",
    "# plt_t = 150\n",
    "vmin = u_p[plt_t,...,::plt_zgap,0].min()\n",
    "vmax = u_p[plt_t,...,::plt_zgap,0].max()\n",
    "vminp = u_p[plt_t,...,::plt_zgap,-1].min()\n",
    "vmaxp = u_p[plt_t,...,::plt_zgap,-1].max()\n",
    "fig,axes = plt.subplots(6,5,figsize=(15,13),height_ratios=(0.16,0.16,0.16,0.16,0.16,0.1))\n",
    "fig.suptitle(f'mdl3 high frequency. Top 2: ref and pred u1, bottom 2: red and pred p. Trained on z={z1} to {z2}.')\n",
    "for i in range(5):\n",
    "    axes[5,i].plot(inns[plt_t,:,i*plt_zgap])\n",
    "    axes[5,i].plot(predv3[inns_loc][plt_t,:,i*plt_zgap],'--')\n",
    "    axes[5,i].set(xlabel=f'y at z={i*plt_zgap}, t={plt_t}', ylim=[inns[plt_t,:,::plt_zgap].min(), inns[plt_t,:,::plt_zgap].max()])\n",
    "    axes[0,i].imshow(u_p[plt_t,:,:,i*plt_zgap,0].T, vmin=vmin, vmax=vmax)\n",
    "    axes[0,i].set(xlabel='x')\n",
    "    axes[1,i].imshow(predv2_2_lowfreq[plt_t,:,:,i*plt_zgap,0].T, vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='x')\n",
    "    axes[2,i].imshow(predv3[plt_t,:,:,i*plt_zgap,0].T, vmin=vmin, vmax=vmax)\n",
    "    axes[2,i].set(xlabel='x')\n",
    "    axes[3,i].imshow(u_p[plt_t,:,:,i*plt_zgap,-1].T, vmin=vminp, vmax=vmaxp)\n",
    "    axes[3,i].set(xlabel='x')\n",
    "    axes[4,i].imshow(predv3[plt_t,:,:,i*plt_zgap,-1].T, vmin=vminp, vmax=vmaxp)\n",
    "    axes[4,i].set(xlabel='x')\n",
    "axes[1,0].set_ylabel('y, low freq mdlv2-2')\n",
    "axes[2,0].set_ylabel('y')\n",
    "axes[3,0].set_ylabel('y')\n",
    "axes[4,0].set_ylabel('y')\n",
    "axes[5,0].set_ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2,4,sharex=True,sharey=True,figsize=(5,2.5))\n",
    "fig.suptitle(f'At z={z_plane}, t={plt_t}')\n",
    "for i in range(4):\n",
    "    imref = axes[0,i].imshow(u_p[plt_t,:,:,z_plane,i].T)\n",
    "    vmin,vmax = imref.get_clim()\n",
    "    axes[1,i].imshow(predv3[plt_t,:,:,z_plane,i].T, vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='x')\n",
    "axes[0,0].set_ylabel('y')\n",
    "axes[1,0].set_ylabel('y')\n",
    "\n",
    "fig,axes = plt.subplots(2,4,sharex=True,sharey=True,figsize=(5,2.5))\n",
    "fig.suptitle(f'At x={0}, t={plt_t}')\n",
    "for i in range(4):\n",
    "    imref = axes[0,i].imshow(u_p[plt_t,0,:,:,i])\n",
    "    vmin,vmax = imref.get_clim()\n",
    "    axes[1,i].imshow(predv3[plt_t,0,:,:,i], vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='z')\n",
    "axes[0,0].set_ylabel('z')\n",
    "axes[1,0].set_ylabel('y')\n",
    "\n",
    "fig,axes = plt.subplots(2,4,sharex=True,sharey=True,figsize=(5,2.5))\n",
    "fig.suptitle(f'At z={z_plane}, time average')\n",
    "for i in range(4):\n",
    "    imref = axes[0,i].imshow(np.mean(u_p[:,:,:,z_plane,i],axis=0).T)\n",
    "    vmin,vmax = imref.get_clim()\n",
    "    axes[1,i].imshow(np.mean(predv3[:,:,:,z_plane,i],axis=0).T, vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='x')\n",
    "axes[0,0].set_ylabel('y')\n",
    "axes[1,0].set_ylabel('y')\n",
    "\n",
    "fig,axes = plt.subplots(2,4,sharex=True,sharey=True,figsize=(5,2.5))\n",
    "fig.suptitle(f'At x={0}, time average')\n",
    "for i in range(4):\n",
    "    imref = axes[0,i].imshow(np.mean(u_p[:,0,:,:,i],axis=0))\n",
    "    vmin,vmax = imref.get_clim()\n",
    "    axes[1,i].imshow(np.mean(predv3[:,0,:,:,i],axis=0), vmin=vmin, vmax=vmax)\n",
    "    axes[1,i].set(xlabel='z')\n",
    "axes[0,0].set_ylabel('z')\n",
    "axes[1,0].set_ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_predv3 = jnp.fft.rfftn(predv3[...,z1:z2,:]-jnp.mean(predv3[...,z1:z2,:],axis=0),axes=[1,2])\n",
    "fe_ref = jnp.fft.rfftn(u_p[...,z1:z2,:]-jnp.mean(u_p[...,z1:z2,:],axis=0),axes=[1,2])\n",
    "fig,axes = plt.subplots(2,4,figsize=(9,3),sharex='all',sharey='all')\n",
    "for i in range(4):\n",
    "    im0 = axes[0,i].imshow(np.sum(np.abs(fe_ref[:,:33,:33,:,i]),axis=(0,3)),extent=(0,fftfreq.max(),0,fftfreq.max()),norm=LogNorm())\n",
    "    # axes[0,i].imshow(np.zeros_like(lowpass[:33,:33]),alpha=lowpass[:33,:33]*0.3,origin='lower',extent=(0,fftfreq.max(),0,fftfreq.max()))\n",
    "    plt.colorbar(im0,ax=axes[0,i])\n",
    "    im1 = axes[1,i].imshow(np.sum(np.abs(fe_predv3[:,:33,:33,:,i]),axis=(0,3)),extent=(0,fftfreq.max(),0,fftfreq.max()),norm=LogNorm())\n",
    "    plt.colorbar(im1,ax=axes[1,i])\n",
    "    # axes[1,i].imshow(np.zeros_like(lowpass[:33,:33]),alpha=lowpass[:33,:33]*0.3,origin='lower',extent=(0,fftfreq.max(),0,fftfreq.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fig1,_),(fig2,axes) = plot_stats(predv3, u_p[...,:-1])\n",
    "spectrum_pretrain2, kbins = derivatives.get_tke(predv2_2-np.mean(predv2_2,axis=0), datainfo)\n",
    "axes[3].loglog(kbins, spectrum_pretrain2, label='mdl2-2',linestyle=':')\n",
    "k_nyquist = (2*np.pi / np.sqrt(2*(datainfo.dx**2))) / 2.\n",
    "axes[3].grid()\n",
    "axes[3].vlines(k_nyquist,10**-13, 10**8, 'k')\n",
    "# axes[3].set_xlim([0.1, k_nyquist])\n",
    "axes[3].legend()\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "counts_true,bins_true = np.histogram(u_p[...,-1].flatten()-np.mean(u_p[...,0].flatten()), density=True, bins='auto')\n",
    "plt.stairs(counts_true,bins_true,label='true',linewidth=3, color='#808080',alpha=0.5)\n",
    "counts_pred, bins_pred = np.histogram(predv2_2[...,-1].flatten()-np.mean(predv2_2[...,0].flatten()), density=True, bins='auto')\n",
    "counts_prednew, bins_prednew = np.histogram(predv3[...,-1].flatten()-np.mean(predv3[...,0].flatten()), density=True, bins='auto')\n",
    "plt.stairs(counts_prednew,bins_prednew,label='mdl3')\n",
    "plt.stairs(counts_pred,bins_pred,label='mdl2-2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print_losses(predv3,u_p[:predv3.shape[0],...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get low frequency data\n",
    "_pred = np.fft.rfftn(predv3, axes=[1,2])\n",
    "predv3_lowfreq = np.fft.irfft2(_pred*lowpass_filter[np.newaxis,:,:,np.newaxis,np.newaxis],axes=[1,2])\n",
    "predv3_highfreq = np.fft.irfft2(_pred*highpass_filter[np.newaxis,:,:,np.newaxis,np.newaxis],axes=[1,2])\n",
    "print(predv2_2_lowfreq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(4,4,figsize=(6,6))\n",
    "for i in range(4):\n",
    "    axes[0,i].imshow(ref_lowfreq[plt_t,:,:,pltz,i].T)\n",
    "    axes[1,i].imshow(ref_highfreq[plt_t,:,:,pltz,i].T)\n",
    "    axes[2,i].imshow(predv3_lowfreq[plt_t,:,:,pltz,i].T)\n",
    "    axes[3,i].imshow(predv3_highfreq[plt_t,:,:,pltz,i].T)\n",
    "fig.suptitle(f'At t={plt_t}, z={pltz}. From top: ref low frequency, high frequency, mdlv3 low frequency, high frequency')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
